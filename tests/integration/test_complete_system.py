#!/usr/bin/env python3
"""
Fragrance AI ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
ì „ì²´ ì‹œìŠ¤í…œì˜ End-to-End ê¸°ëŠ¥ ê²€ì¦
"""

import asyncio
import pytest
import httpx
import json
import logging
from typing import Dict, List, Any, Optional
import time
from datetime import datetime
from pathlib import Path

# í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ëª¨ë“ˆë“¤
from fragrance_ai.api.main import app
from fragrance_ai.core.config import settings
from fragrance_ai.models.embedding import AdvancedKoreanFragranceEmbedding
from fragrance_ai.models.generator import FragranceRecipeGenerator
from fragrance_ai.core.vector_store import VectorStore
from fragrance_ai.database.connection import get_db_session
from fragrance_ai.services.search_service import SearchService
from fragrance_ai.services.generation_service import GenerationService
from fragrance_ai.evaluation.advanced_evaluator import AdvancedModelEvaluator
from fragrance_ai.utils.web_scraper import FragranceDataScraper
from fragrance_ai.utils.data_cleaner import FragranceDataCleaner

logger = logging.getLogger(__name__)

@pytest.mark.asyncio
class TestCompleteSystemIntegration:
    """ì™„ì „í•œ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.fixture(autouse=True)
    async def setup_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.base_url = f"http://localhost:{settings.api_port}"
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0),
            follow_redirects=True
        )

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.embedding_model = AdvancedKoreanFragranceEmbedding()
        self.generator = FragranceRecipeGenerator()
        self.vector_store = VectorStore()
        self.search_service = SearchService()
        self.generation_service = GenerationService()
        self.evaluator = AdvancedModelEvaluator()

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        self.test_data = await self._prepare_test_data()

        yield

        # ì •ë¦¬
        await self.client.aclose()

    async def _prepare_test_data(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        return {
            'test_queries': [
                'ë”°ëœ»í•˜ê³  ë‹¬ì½¤í•œ ê²¨ìš¸ í–¥ìˆ˜',
                'ìƒì¾Œí•œ ì‹œíŠ¸ëŸ¬ìŠ¤ ì—¬ë¦„ í–¥ìˆ˜',
                'ìš°ì•„í•œ í”Œë¡œëŸ´ ë°ì´íŠ¸ í–¥ìˆ˜',
                'ê¹Šê³  ì‹ ë¹„ë¡œìš´ ë°¤ í–¥ìˆ˜',
                'ê°€ë²¼ìš´ ì¼ìƒ í–¥ìˆ˜'
            ],
            'test_generation_prompts': [
                {
                    'prompt': 'ë¡œë§¨í‹±í•œ ë°ì´íŠ¸ë¥¼ ìœ„í•œ í–¥ìˆ˜',
                    'mood': 'romantic',
                    'season': 'spring'
                },
                {
                    'prompt': 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¯¸íŒ…ì— ì í•©í•œ í–¥ìˆ˜',
                    'mood': 'professional',
                    'season': 'all'
                },
                {
                    'prompt': 'íŒŒí‹°ì—ì„œ ë‹ë³´ì´ëŠ” í–¥ìˆ˜',
                    'mood': 'energetic',
                    'season': 'winter'
                }
            ],
            'expected_response_fields': [
                'results', 'total_results', 'query', 'search_time'
            ]
        }

    async def test_system_health_check(self):
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing system health check...")

        response = await self.client.get(f"{self.base_url}/health")

        assert response.status_code == 200
        health_data = response.json()

        assert health_data['status'] == 'healthy'
        assert 'models' in health_data
        assert health_data['models']['vector_store'] == True
        assert health_data['models']['embedding_model'] == True
        assert health_data['models']['generator'] == True

        logger.info("âœ… System health check passed")

    async def test_embedding_model_functionality(self):
        """ì„ë² ë”© ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing embedding model functionality...")

        start_time = time.time()

        # ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©
        test_text = "í†°í¬ë“œ ë¸”ë™ ì˜¤í‚¤ë“œëŠ” ê´€ëŠ¥ì ì´ê³  ì‹ ë¹„ë¡œìš´ í–¥ìˆ˜ì…ë‹ˆë‹¤"
        embedding_result = await self.embedding_model.encode_async([test_text])

        assert embedding_result.embeddings.shape[0] == 1
        assert embedding_result.embeddings.shape[1] > 0  # ì°¨ì› í™•ì¸
        assert embedding_result.processing_time > 0

        # ë°°ì¹˜ ì„ë² ë”©
        test_texts = self.test_data['test_queries']
        batch_result = await self.embedding_model.encode_async(test_texts)

        assert batch_result.embeddings.shape[0] == len(test_texts)
        assert batch_result.embeddings.shape[1] > 0

        # ë‹¤ë©´ì  ì„ë² ë”©
        multi_aspect_result = self.embedding_model.encode_multi_aspect(test_texts[:2])

        assert 'base' in multi_aspect_result
        assert len(multi_aspect_result['base']) == 2

        processing_time = time.time() - start_time
        logger.info(f"âœ… Embedding model test passed (took {processing_time:.2f}s)")

    async def test_generation_model_functionality(self):
        """ìƒì„± ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing generation model functionality...")

        start_time = time.time()

        for prompt_data in self.test_data['test_generation_prompts']:
            # ë ˆì‹œí”¼ ìƒì„±
            recipe = self.generator.generate_recipe(
                prompt=prompt_data['prompt'],
                recipe_type='detailed',
                mood=prompt_data['mood'],
                season=prompt_data['season']
            )

            # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
            assert 'name' in recipe
            assert 'description' in recipe
            assert 'top_notes' in recipe
            assert 'heart_notes' in recipe
            assert 'base_notes' in recipe
            assert 'instructions' in recipe

            # ë‚´ìš© ê²€ì¦
            assert len(recipe['name']) > 0
            assert len(recipe['description']) > 10
            assert len(recipe['top_notes']) > 0
            assert len(recipe['heart_notes']) > 0
            assert len(recipe['base_notes']) > 0

            # í’ˆì§ˆ í‰ê°€
            quality_scores = self.generator.evaluate_recipe_quality(recipe)
            assert 'overall' in quality_scores
            assert 0 <= quality_scores['overall'] <= 1

            logger.info(f"Generated recipe: {recipe['name']} (quality: {quality_scores['overall']:.2f})")

        processing_time = time.time() - start_time
        logger.info(f"âœ… Generation model test passed (took {processing_time:.2f}s)")

    async def test_vector_store_functionality(self):
        """ë²¡í„° ìŠ¤í† ì–´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing vector store functionality...")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_documents = []
        for i, query in enumerate(self.test_data['test_queries']):
            embedding = await self.embedding_model.encode_async([query])
            test_documents.append({
                'id': f'test_doc_{i}',
                'embedding': embedding.embeddings[0].tolist(),
                'metadata': {
                    'text': query,
                    'type': 'test',
                    'index': i
                }
            })

        # ë¬¸ì„œ ì¶”ê°€
        self.vector_store.batch_add_documents(
            collection_name="test_collection",
            documents=test_documents
        )

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        for query in self.test_data['test_queries'][:2]:
            results = self.vector_store.semantic_search(
                collection_name="test_collection",
                query=query,
                top_k=3
            )

            assert len(results) > 0
            assert len(results) <= 3

            for result in results:
                assert 'id' in result
                assert 'score' in result
                assert 'metadata' in result
                assert 0 <= result['score'] <= 1

        # ì»¬ë ‰ì…˜ í†µê³„
        stats = self.vector_store.get_collection_stats("test_collection")
        assert stats['count'] == len(test_documents)

        logger.info("âœ… Vector store test passed")

    async def test_search_api_endpoint(self):
        """ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing search API endpoint...")

        for query in self.test_data['test_queries']:
            # ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ API í˜¸ì¶œ
            response = await self.client.post(
                f"{self.base_url}/api/v1/semantic-search",
                json={
                    'query': query,
                    'search_type': 'hybrid',
                    'top_k': 5,
                    'collections': ['fragrance_notes', 'recipes']
                }
            )

            assert response.status_code == 200

            result = response.json()

            # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
            for field in self.test_data['expected_response_fields']:
                assert field in result

            assert isinstance(result['results'], list)
            assert isinstance(result['total_results'], int)
            assert result['query'] == query
            assert result['search_time'] > 0

            # ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
            if len(result['results']) > 0:
                for item in result['results']:
                    assert 'id' in item
                    assert 'score' in item
                    assert 'metadata' in item
                    assert 0 <= item['score'] <= 1

            logger.info(f"Search query '{query}' returned {len(result['results'])} results")

        logger.info("âœ… Search API test passed")

    async def test_generation_api_endpoint(self):
        """ìƒì„± API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing generation API endpoint...")

        for prompt_data in self.test_data['test_generation_prompts']:
            response = await self.client.post(
                f"{self.base_url}/api/v1/generate-recipe",
                json={
                    'prompt': prompt_data['prompt'],
                    'recipe_type': 'detailed',
                    'mood': prompt_data['mood'],
                    'season': prompt_data['season'],
                    'include_story': True
                }
            )

            assert response.status_code == 200

            result = response.json()

            # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
            assert 'recipe' in result
            assert 'quality_scores' in result
            assert 'generation_time' in result
            assert 'prompt' in result

            recipe = result['recipe']
            assert 'name' in recipe
            assert 'description' in recipe
            assert 'top_notes' in recipe
            assert 'heart_notes' in recipe
            assert 'base_notes' in recipe

            quality_scores = result['quality_scores']
            assert 'overall' in quality_scores
            assert 0 <= quality_scores['overall'] <= 1

            logger.info(f"Generated recipe API: {recipe['name']} (quality: {quality_scores['overall']:.2f})")

        logger.info("âœ… Generation API test passed")

    async def test_batch_generation_api(self):
        """ë°°ì¹˜ ìƒì„± API í…ŒìŠ¤íŠ¸"""
        logger.info("Testing batch generation API...")

        prompts = [data['prompt'] for data in self.test_data['test_generation_prompts']]

        response = await self.client.post(
            f"{self.base_url}/api/v1/batch-generate",
            json={
                'prompts': prompts,
                'batch_size': 2
            }
        )

        assert response.status_code == 200

        result = response.json()

        assert 'recipes' in result
        assert 'total_recipes' in result
        assert 'average_quality' in result
        assert 'generation_time' in result

        assert len(result['recipes']) == len(prompts)
        assert result['total_recipes'] == len(prompts)
        assert 0 <= result['average_quality'] <= 1

        for recipe in result['recipes']:
            assert 'name' in recipe
            assert 'description' in recipe
            assert len(recipe['name']) > 0
            assert len(recipe['description']) > 10

        logger.info(f"âœ… Batch generation API test passed ({len(result['recipes'])} recipes)")

    async def test_database_integration(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""
        logger.info("Testing database integration...")

        try:
            async for session in get_db_session():
                # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
                result = await session.execute("SELECT COUNT(*) as count FROM fragrance_notes")
                count_result = result.fetchone()

                assert count_result is not None

                # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
                result = await session.execute("SELECT * FROM fragrance_notes LIMIT 5")
                sample_data = result.fetchall()

                logger.info(f"Database contains {count_result.count if count_result else 0} fragrance records")
                logger.info(f"Sample data retrieved: {len(sample_data)} records")

                break
        except Exception as e:
            pytest.fail(f"Database integration test failed: {e}")

        logger.info("âœ… Database integration test passed")

    async def test_end_to_end_workflow(self):
        """End-to-End ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        logger.info("Testing end-to-end workflow...")

        start_time = time.time()

        # 1. ê²€ìƒ‰ ìˆ˜í–‰
        search_query = "ë¡œë§¨í‹±í•œ ì¥ë¯¸ í–¥ìˆ˜"
        search_response = await self.client.post(
            f"{self.base_url}/api/v1/semantic-search",
            json={
                'query': search_query,
                'search_type': 'hybrid',
                'top_k': 3
            }
        )

        assert search_response.status_code == 200
        search_results = search_response.json()

        # 2. ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë ˆì‹œí”¼ ìƒì„±
        generation_prompt = f"{search_query}ì™€ ìœ ì‚¬í•œ í–¥ìˆ˜ ë ˆì‹œí”¼ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
        generation_response = await self.client.post(
            f"{self.base_url}/api/v1/generate-recipe",
            json={
                'prompt': generation_prompt,
                'recipe_type': 'premium',
                'mood': 'romantic',
                'include_story': True
            }
        )

        assert generation_response.status_code == 200
        generation_results = generation_response.json()

        # 3. ìƒì„±ëœ ë ˆì‹œí”¼ í’ˆì§ˆ ê²€ì¦
        recipe = generation_results['recipe']
        quality_scores = generation_results['quality_scores']

        assert quality_scores['overall'] > 0.5  # ìµœì†Œ í’ˆì§ˆ ê¸°ì¤€

        # 4. ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ í™•ì¸
        metrics_response = await self.client.get(
            f"{self.base_url}/metrics",
            headers={'Authorization': 'Bearer test-token'}
        )

        # ì¸ì¦ì´ ì—†ì–´ë„ ê³„ì† ì§„í–‰ (ì„ íƒì )
        if metrics_response.status_code == 200:
            metrics = metrics_response.json()
            logger.info(f"System metrics: {metrics.get('system', {})}")

        total_time = time.time() - start_time

        logger.info(f"âœ… End-to-end workflow completed in {total_time:.2f}s")
        logger.info(f"Search found {len(search_results.get('results', []))} results")
        logger.info(f"Generated recipe: '{recipe['name']}' with quality {quality_scores['overall']:.2f}")

    async def test_performance_benchmarks(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing performance benchmarks...")

        # ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        search_times = []
        for query in self.test_data['test_queries']:
            start_time = time.time()

            response = await self.client.post(
                f"{self.base_url}/api/v1/semantic-search",
                json={'query': query, 'top_k': 5}
            )

            end_time = time.time()
            search_time = end_time - start_time
            search_times.append(search_time)

            assert response.status_code == 200
            assert search_time < 3.0  # 3ì´ˆ ì´ë‚´

        avg_search_time = sum(search_times) / len(search_times)

        # ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        generation_times = []
        for prompt_data in self.test_data['test_generation_prompts']:
            start_time = time.time()

            response = await self.client.post(
                f"{self.base_url}/api/v1/generate-recipe",
                json={
                    'prompt': prompt_data['prompt'],
                    'recipe_type': 'basic'
                }
            )

            end_time = time.time()
            generation_time = end_time - start_time
            generation_times.append(generation_time)

            assert response.status_code == 200
            assert generation_time < 10.0  # 10ì´ˆ ì´ë‚´

        avg_generation_time = sum(generation_times) / len(generation_times)

        logger.info(f"âœ… Performance benchmarks:")
        logger.info(f"  Average search time: {avg_search_time:.2f}s")
        logger.info(f"  Average generation time: {avg_generation_time:.2f}s")

        # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
        assert avg_search_time < 2.0  # í‰ê·  ê²€ìƒ‰ ì‹œê°„ 2ì´ˆ ì´ë‚´
        assert avg_generation_time < 8.0  # í‰ê·  ìƒì„± ì‹œê°„ 8ì´ˆ ì´ë‚´

    async def test_error_handling(self):
        """ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing error handling...")

        # ì˜ëª»ëœ ê²€ìƒ‰ ìš”ì²­
        response = await self.client.post(
            f"{self.base_url}/api/v1/semantic-search",
            json={'invalid_field': 'test'}
        )
        assert response.status_code in [400, 422]

        # ë¹ˆ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        response = await self.client.post(
            f"{self.base_url}/api/v1/semantic-search",
            json={'query': '', 'top_k': 5}
        )
        # ë¹ˆ ì¿¼ë¦¬ëŠ” ì²˜ë¦¬ë  ìˆ˜ ìˆìŒ
        assert response.status_code in [200, 400]

        # ë„ˆë¬´ ê¸´ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
        very_long_prompt = "í–¥ìˆ˜ " * 1000
        response = await self.client.post(
            f"{self.base_url}/api/v1/generate-recipe",
            json={'prompt': very_long_prompt}
        )
        # ì„œë²„ê°€ ì ì ˆíˆ ì²˜ë¦¬í•˜ëŠ”ì§€ í™•ì¸
        assert response.status_code in [200, 400, 413]

        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸
        response = await self.client.get(f"{self.base_url}/api/v1/nonexistent")
        assert response.status_code == 404

        logger.info("âœ… Error handling test passed")

    async def test_data_consistency(self):
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        logger.info("Testing data consistency...")

        # ë™ì¼í•œ ì¿¼ë¦¬ë¡œ ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰í•˜ì—¬ ì¼ê´€ì„± í™•ì¸
        test_query = self.test_data['test_queries'][0]
        results = []

        for _ in range(3):
            response = await self.client.post(
                f"{self.base_url}/api/v1/semantic-search",
                json={'query': test_query, 'top_k': 5}
            )
            assert response.status_code == 200
            results.append(response.json())

            await asyncio.sleep(0.1)  # ì§§ì€ ëŒ€ê¸°

        # ê²°ê³¼ ì¼ê´€ì„± ê²€ì¦
        for i in range(1, len(results)):
            assert results[0]['total_results'] == results[i]['total_results']

            # ìƒìœ„ ê²°ê³¼ ìˆœì„œ ì¼ê´€ì„± (ì•½ê°„ì˜ ë³€ë™ì€ í—ˆìš©)
            if len(results[0]['results']) > 0 and len(results[i]['results']) > 0:
                top_result_0 = results[0]['results'][0]['id']
                top_result_i = results[i]['results'][0]['id']
                # ë™ì¼í•˜ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬í•œ ì ìˆ˜ì—¬ì•¼ í•¨
                assert abs(results[0]['results'][0]['score'] - results[i]['results'][0]['score']) < 0.01

        logger.info("âœ… Data consistency test passed")

    async def test_concurrent_requests(self):
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing concurrent request handling...")

        async def make_search_request(query: str):
            response = await self.client.post(
                f"{self.base_url}/api/v1/semantic-search",
                json={'query': query, 'top_k': 3}
            )
            return response.status_code, response.json()

        # ë™ì‹œì— ì—¬ëŸ¬ ê²€ìƒ‰ ìš”ì²­ ì‹¤í–‰
        tasks = [
            make_search_request(query)
            for query in self.test_data['test_queries']
        ]

        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()

        # ëª¨ë“  ìš”ì²­ì´ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
        for result in results:
            if isinstance(result, Exception):
                pytest.fail(f"Concurrent request failed: {result}")

            status_code, response_data = result
            assert status_code == 200
            assert 'results' in response_data

        total_time = end_time - start_time
        avg_time_per_request = total_time / len(tasks)

        logger.info(f"âœ… Concurrent requests test passed")
        logger.info(f"  {len(tasks)} requests completed in {total_time:.2f}s")
        logger.info(f"  Average time per request: {avg_time_per_request:.2f}s")

        # ë™ì‹œ ì²˜ë¦¬ê°€ ìˆœì°¨ ì²˜ë¦¬ë³´ë‹¤ íš¨ìœ¨ì ì¸ì§€ í™•ì¸
        assert total_time < len(tasks) * 2.0  # ìˆœì°¨ ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„ë³´ë‹¤ ì§§ì•„ì•¼ í•¨

    async def test_system_scalability(self):
        """ì‹œìŠ¤í…œ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ (ë¶€í•˜ í…ŒìŠ¤íŠ¸)"""
        logger.info("Testing system scalability...")

        # ì ì§„ì ìœ¼ë¡œ ë¶€í•˜ ì¦ê°€
        load_levels = [5, 10, 15]

        for load_level in load_levels:
            logger.info(f"Testing with {load_level} concurrent requests...")

            async def make_request():
                query = self.test_data['test_queries'][0]
                response = await self.client.post(
                    f"{self.base_url}/api/v1/semantic-search",
                    json={'query': query, 'top_k': 3}
                )
                return response.status_code == 200, response.elapsed.total_seconds()

            # ë™ì‹œ ìš”ì²­ ì‹¤í–‰
            start_time = time.time()
            tasks = [make_request() for _ in range(load_level)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            end_time = time.time()

            # ê²°ê³¼ ë¶„ì„
            successful_requests = 0
            total_response_time = 0

            for result in results:
                if isinstance(result, Exception):
                    logger.warning(f"Request failed with exception: {result}")
                    continue

                success, response_time = result
                if success:
                    successful_requests += 1
                    total_response_time += response_time

            success_rate = successful_requests / load_level
            avg_response_time = total_response_time / max(successful_requests, 1)
            throughput = successful_requests / (end_time - start_time)

            logger.info(f"  Load level {load_level}: {success_rate:.1%} success rate")
            logger.info(f"  Average response time: {avg_response_time:.2f}s")
            logger.info(f"  Throughput: {throughput:.1f} requests/sec")

            # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
            assert success_rate >= 0.9  # 90% ì´ìƒ ì„±ê³µë¥ 
            assert avg_response_time < 5.0  # 5ì´ˆ ì´ë‚´ ì‘ë‹µ

        logger.info("âœ… System scalability test passed")


async def run_integration_tests():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("\n" + "="*60)
    print("ğŸš€ FRAGRANCE AI ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)

    test_instance = TestCompleteSystemIntegration()

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    await test_instance.setup_system()

    tests = [
        ("ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬", test_instance.test_system_health_check),
        ("ì„ë² ë”© ëª¨ë¸ ê¸°ëŠ¥", test_instance.test_embedding_model_functionality),
        ("ìƒì„± ëª¨ë¸ ê¸°ëŠ¥", test_instance.test_generation_model_functionality),
        ("ë²¡í„° ìŠ¤í† ì–´ ê¸°ëŠ¥", test_instance.test_vector_store_functionality),
        ("ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸", test_instance.test_search_api_endpoint),
        ("ìƒì„± API ì—”ë“œí¬ì¸íŠ¸", test_instance.test_generation_api_endpoint),
        ("ë°°ì¹˜ ìƒì„± API", test_instance.test_batch_generation_api),
        ("ë°ì´í„°ë² ì´ìŠ¤ í†µí•©", test_instance.test_database_integration),
        ("End-to-End ì›Œí¬í”Œë¡œìš°", test_instance.test_end_to_end_workflow),
        ("ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬", test_instance.test_performance_benchmarks),
        ("ì—ëŸ¬ í•¸ë“¤ë§", test_instance.test_error_handling),
        ("ë°ì´í„° ì¼ê´€ì„±", test_instance.test_data_consistency),
        ("ë™ì‹œ ìš”ì²­ ì²˜ë¦¬", test_instance.test_concurrent_requests),
        ("ì‹œìŠ¤í…œ í™•ì¥ì„±", test_instance.test_system_scalability),
    ]

    passed_tests = 0
    failed_tests = 0
    start_time = time.time()

    for test_name, test_func in tests:
        try:
            print(f"\nğŸ” {test_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
            await test_func()
            passed_tests += 1

        except Exception as e:
            print(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            failed_tests += 1
            logger.error(f"Test {test_name} failed", exc_info=True)

    total_time = time.time() - start_time

    print(f"\n" + "="*60)
    print("ğŸ“Š í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(tests)}")
    print(f"í†µê³¼: {passed_tests} âœ…")
    print(f"ì‹¤íŒ¨: {failed_tests} âŒ")
    print(f"ì„±ê³µë¥ : {passed_tests/len(tests)*100:.1f}%")
    print(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ")

    if failed_tests == 0:
        print("\nğŸ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("âœ¨ Fragrance AI ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâš ï¸  {failed_tests}ê°œì˜ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ”§ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”.")

    print("="*60)

    return failed_tests == 0


if __name__ == "__main__":
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(run_integration_tests())