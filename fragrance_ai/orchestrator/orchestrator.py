"""
LLM Orchestrator - The Central Brain of the Agentic RAG System
- Orchestrates tool execution based on user requests
- Implements the agentic workflow with planning, execution, and synthesis
- Provides self-correction capabilities through iterative refinement
"""

import logging
import json
import uuid
import time
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
import asyncio
from dataclasses import dataclass

from ..tools.hybrid_search_tool import hybrid_search, MetadataFilters
from ..tools.scientific_validator_tool import validate_composition, NotesComposition
from ..tools.perfumer_knowledge_tool import query_knowledge_base
# from ..core.exceptions import handle_exceptions_async
from ..models.conversation_llm import get_conversation_llm
from ..models.generator import FragranceRecipeGenerator

logger = logging.getLogger(__name__)

@dataclass
class ExecutionPlan:
    """Represents a step-by-step execution plan for a user request."""
    request_id: str
    user_query: str
    intent_analysis: str
    planned_steps: List[Dict[str, Any]]
    expected_tools: List[str]
    complexity_level: str  # simple, moderate, complex
    estimated_duration: float  # seconds

@dataclass
class ToolExecution:
    """Represents the execution of a single tool."""
    tool_name: str
    parameters: Dict[str, Any]
    result: Any
    execution_time: float
    success: bool
    error_message: Optional[str] = None

@dataclass
class OrchestratorResponse:
    """Final response from the orchestrator."""
    request_id: str
    success: bool
    response: str
    execution_plan: ExecutionPlan
    tool_executions: List[ToolExecution]
    total_execution_time: float
    metadata: Dict[str, Any]

class LLMOrchestrator:
    """
    The Central Orchestrator that acts as the 'Master Perfumer's Brain'.
    Analyzes user requests, formulates execution plans, and orchestrates tool usage.
    """

    def __init__(self):
        self.session_id = str(uuid.uuid4())
        self.conversation_history = []
        self.tool_registry = {
            "hybrid_search": hybrid_search,
            "validate_composition": validate_composition,
            "query_knowledge_base": query_knowledge_base
        }
        self.max_iterations = 3  # For self-correction loops
        self.current_query = ""  # Store current query for LLM context

        # Initialize Real LLM Systems
        self.conversation_llm = get_conversation_llm()  # ì§„ì§œ ëŒ€í™”í˜• LLM
        self.recipe_generator = FragranceRecipeGenerator()  # ì§„ì§œ í–¥ìˆ˜ ìƒì„± LLM
        logger.info("ì§„ì§œ LLM ì‹œìŠ¤í…œë“¤ ì´ˆê¸°í™” ì™„ë£Œ - ëŒ€í™”í˜• LLM + ë ˆì‹œí”¼ ìƒì„± LLM")

    async def process_request(self, user_query: str, context: Optional[Dict[str, Any]] = None) -> OrchestratorResponse:
        """
        Main entry point for processing user requests.
        Implements the complete agentic workflow.
        """
        start_time = time.time()
        request_id = str(uuid.uuid4())
        self.current_query = user_query  # Store for LLM context

        try:
            # Step 1: Analyze intent and create execution plan
            execution_plan = await self._create_execution_plan(request_id, user_query, context)

            # Step 2: Execute the plan with tool orchestration
            tool_executions = await self._execute_plan(execution_plan)

            # Step 3: Synthesize results into final response
            final_response = await self._synthesize_response(execution_plan, tool_executions)

            total_time = time.time() - start_time

            # Create orchestrator response
            response = OrchestratorResponse(
                request_id=request_id,
                success=True,
                response=final_response,
                execution_plan=execution_plan,
                tool_executions=tool_executions,
                total_execution_time=total_time,
                metadata={
                    "session_id": self.session_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "tools_used": list(set(exec.tool_name for exec in tool_executions)),
                    "iterations": len(tool_executions)
                }
            )

            # Store in conversation history
            self.conversation_history.append({
                "user_query": user_query,
                "response": response,
                "timestamp": datetime.utcnow().isoformat()
            })

            logger.info(f"Request {request_id} completed successfully in {total_time:.2f}s")
            return response

        except Exception as e:
            total_time = time.time() - start_time
            logger.error(f"Request {request_id} failed: {e}")

            return OrchestratorResponse(
                request_id=request_id,
                success=False,
                response=f"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                execution_plan=None,
                tool_executions=[],
                total_execution_time=total_time,
                metadata={"error": str(e)}
            )

    async def _create_execution_plan(self, request_id: str, user_query: str, context: Optional[Dict[str, Any]]) -> ExecutionPlan:
        """
        Analyze the user request and create a detailed execution plan.
        This simulates the LLM's planning capabilities.
        """
        # Analyze intent (simplified - in real implementation, this would use LLM)
        intent_analysis = await self._analyze_intent(user_query)

        planned_steps = []
        expected_tools = []

        # Determine execution strategy based on intent
        if "ì¶”ì²œ" in user_query or "ì°¾ì•„" in user_query or "recommend" in user_query.lower():
            # Recommendation flow
            planned_steps.extend([
                {
                    "step": 1,
                    "action": "search_existing_perfumes",
                    "tool": "hybrid_search",
                    "purpose": "Find existing perfumes matching the request"
                },
                {
                    "step": 2,
                    "action": "synthesize_recommendations",
                    "tool": None,
                    "purpose": "Create personalized recommendations"
                }
            ])
            expected_tools.extend(["hybrid_search"])

        elif "ë§Œë“¤ì–´" in user_query or "ìƒì„±" in user_query or "create" in user_query.lower():
            # Creation flow
            planned_steps.extend([
                {
                    "step": 1,
                    "action": "gather_inspiration",
                    "tool": "hybrid_search",
                    "purpose": "Research existing perfumes for inspiration"
                },
                {
                    "step": 2,
                    "action": "check_perfumer_style",
                    "tool": "query_knowledge_base",
                    "purpose": "Get master perfumer knowledge if style mentioned"
                },
                {
                    "step": 3,
                    "action": "create_composition",
                    "tool": None,
                    "purpose": "Generate new fragrance recipe"
                },
                {
                    "step": 4,
                    "action": "validate_recipe",
                    "tool": "validate_composition",
                    "purpose": "Scientific validation and refinement"
                }
            ])
            expected_tools.extend(["hybrid_search", "validate_composition"])

            # Add knowledge base tool if specific perfumer mentioned
            if any(name in user_query.lower() for name in ["jean-claude ellena", "francis kurkdjian", "serge lutens"]):
                expected_tools.append("query_knowledge_base")

        elif "ìŠ¤íƒ€ì¼" in user_query or "ì¡°í™”" in user_query or "accord" in user_query.lower():
            # Knowledge query flow
            planned_steps.extend([
                {
                    "step": 1,
                    "action": "query_perfumer_knowledge",
                    "tool": "query_knowledge_base",
                    "purpose": "Access master perfumer or accord knowledge"
                },
                {
                    "step": 2,
                    "action": "provide_insights",
                    "tool": None,
                    "purpose": "Share knowledge and insights"
                }
            ])
            expected_tools.extend(["query_knowledge_base"])

        # Determine complexity
        complexity = "simple"
        if len(expected_tools) > 1:
            complexity = "moderate"
        if "ê²°í˜¼" in user_query or "íŠ¹ë³„í•œ" in user_query or len(user_query) > 100:
            complexity = "complex"

        # Estimate duration
        estimated_duration = len(planned_steps) * 2.0  # 2 seconds per step average

        return ExecutionPlan(
            request_id=request_id,
            user_query=user_query,
            intent_analysis=intent_analysis,
            planned_steps=planned_steps,
            expected_tools=expected_tools,
            complexity_level=complexity,
            estimated_duration=estimated_duration
        )

    async def _analyze_intent(self, user_query: str) -> str:
        """
        Analyze user intent from the query.
        Simplified implementation - would use LLM in production.
        """
        query_lower = user_query.lower()

        if any(word in query_lower for word in ["ì¶”ì²œ", "ì°¾ì•„", "recommend", "suggest"]):
            return "recommendation_request"
        elif any(word in query_lower for word in ["ë§Œë“¤ì–´", "ìƒì„±", "create", "generate"]):
            return "creation_request"
        elif any(word in query_lower for word in ["ì„¤ëª…", "ì•Œë ¤", "what", "explain"]):
            return "information_request"
        elif any(word in query_lower for word in ["ìŠ¤íƒ€ì¼", "ì¡°í™”", "accord", "style"]):
            return "knowledge_request"
        else:
            return "general_inquiry"

    async def _execute_plan(self, execution_plan: ExecutionPlan) -> List[ToolExecution]:
        """
        Execute the planned steps using appropriate tools.
        Implements the agentic workflow with self-correction.
        """
        tool_executions = []
        context = {"user_query": execution_plan.user_query}

        for step in execution_plan.planned_steps:
            if step["tool"] is None:
                continue  # Skip synthesis steps

            tool_name = step["tool"]

            try:
                execution_start = time.time()

                # Prepare tool parameters based on the step and context
                tool_params = await self._prepare_tool_parameters(tool_name, step, context)

                # Execute the tool
                tool_function = self.tool_registry[tool_name]
                result = await tool_function(**tool_params)

                execution_time = time.time() - execution_start

                # Record successful execution
                tool_execution = ToolExecution(
                    tool_name=tool_name,
                    parameters=tool_params,
                    result=result,
                    execution_time=execution_time,
                    success=True
                )
                tool_executions.append(tool_execution)

                # Update context with results
                context[f"{tool_name}_result"] = result

                # Self-correction logic for validation
                if tool_name == "validate_composition" and hasattr(result, 'harmony_score'):
                    if result.harmony_score < 0.6 and len(tool_executions) < self.max_iterations:
                        # Recipe needs improvement - implement self-correction
                        await self._implement_self_correction(result, context, tool_executions)

            except Exception as e:
                execution_time = time.time() - execution_start

                # Record failed execution
                tool_execution = ToolExecution(
                    tool_name=tool_name,
                    parameters=tool_params if 'tool_params' in locals() else {},
                    result=None,
                    execution_time=execution_time,
                    success=False,
                    error_message=str(e)
                )
                tool_executions.append(tool_execution)

                logger.error(f"Tool {tool_name} execution failed: {e}")

        return tool_executions

    async def _prepare_tool_parameters(self, tool_name: str, step: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Prepare parameters for tool execution based on context and step requirements.
        """
        user_query = context["user_query"]

        if tool_name == "hybrid_search":
            # Extract search criteria from user query
            filters = MetadataFilters()

            # Parse user preferences (simplified)
            if "ì—¬ë¦„" in user_query or "summer" in user_query.lower():
                filters.season = "summer"
            elif "ê²¨ìš¸" in user_query or "winter" in user_query.lower():
                filters.season = "winter"
            elif "ë´„" in user_query or "spring" in user_query.lower():
                filters.season = "spring"
            elif "ê°€ì„" in user_query or "autumn" in user_query.lower():
                filters.season = "autumn"

            if "ë‚¨ì„±" in user_query or "men" in user_query.lower():
                filters.gender = "male"
            elif "ì—¬ì„±" in user_query or "women" in user_query.lower():
                filters.gender = "female"

            # Extract price constraints
            if "ì €ë ´" in user_query or "cheap" in user_query.lower():
                filters.price_less_than = 100
            elif "ê³ ê¸‰" in user_query or "luxury" in user_query.lower():
                filters.price_less_than = None

            # Extract required notes
            notes_mentioned = []
            for note in ["ì¥ë¯¸", "rose", "ë°”ë‹ë¼", "vanilla", "ë¼ë²¤ë”", "lavender"]:
                if note in user_query.lower():
                    notes_mentioned.append(note)

            if notes_mentioned:
                filters.include_notes = notes_mentioned

            return {
                "text_query": user_query,
                "metadata_filters": filters,
                "top_k": 10
            }

        elif tool_name == "validate_composition":
            # Extract composition from context or create from user requirements
            if "composition" in context:
                return {"composition": context["composition"]}
            else:
                # Create a sample composition for validation
                return {
                    "composition": NotesComposition(
                        top=["bergamot", "lemon"],
                        middle=["rose", "jasmine"],
                        base=["sandalwood", "vanilla"]
                    )
                }

        elif tool_name == "query_knowledge_base":
            # Determine what to query
            if any(name in user_query.lower() for name in ["jean-claude ellena", "ellena"]):
                return {"query_type": "perfumer_style", "name": "jean-claude ellena"}
            elif any(name in user_query.lower() for name in ["francis kurkdjian", "kurkdjian"]):
                return {"query_type": "perfumer_style", "name": "francis kurkdjian"}
            elif any(name in user_query.lower() for name in ["serge lutens", "lutens"]):
                return {"query_type": "perfumer_style", "name": "serge lutens"}
            elif "chypre" in user_query.lower() or "ì‹œí”„ë ˆ" in user_query:
                return {"query_type": "accord_formula", "name": "chypre"}
            elif "fougÃ¨re" in user_query.lower() or "í‘¸ì œë¥´" in user_query:
                return {"query_type": "accord_formula", "name": "fougÃ¨re"}
            else:
                return {"query_type": "perfumer_style", "name": "jean-claude ellena"}  # Default

        return {}

    async def _implement_self_correction(self, validation_result, context: Dict[str, Any], tool_executions: List[ToolExecution]):
        """
        Implement self-correction based on validation feedback.
        """
        if hasattr(validation_result, 'suggestions') and validation_result.suggestions:
            # Take the first suggestion and attempt to implement it
            suggestion = validation_result.suggestions[0]

            # This is a simplified implementation
            # In a real system, this would use LLM to interpret suggestions and modify the composition
            if "bridge note" in suggestion.lower():
                # Add a bridge note to the composition
                improved_composition = NotesComposition(
                    top=["bergamot", "lemon", "iris"],  # Added iris as bridge
                    middle=["rose", "jasmine"],
                    base=["sandalwood", "vanilla"]
                )

                # Re-validate the improved composition
                try:
                    new_validation = await validate_composition(improved_composition)

                    correction_execution = ToolExecution(
                        tool_name="validate_composition",
                        parameters={"composition": improved_composition},
                        result=new_validation,
                        execution_time=1.0,
                        success=True
                    )
                    tool_executions.append(correction_execution)

                    # Update context
                    context["improved_composition"] = improved_composition
                    context["final_validation"] = new_validation

                except Exception as e:
                    logger.error(f"Self-correction failed: {e}")

    async def _synthesize_response(self, execution_plan: ExecutionPlan, tool_executions: List[ToolExecution]) -> str:
        """
        Synthesize the final response based on tool execution results.
        This simulates the LLM's synthesis capabilities.
        """
        user_query = execution_plan.user_query

        # Check if this is a Korean query
        is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7AF for char in user_query)

        if execution_plan.intent_analysis == "recommendation_request":
            return await self._synthesize_recommendation_response(tool_executions, is_korean)
        elif execution_plan.intent_analysis == "creation_request":
            return await self._synthesize_creation_response(tool_executions, is_korean)
        elif execution_plan.intent_analysis == "knowledge_request":
            return await self._synthesize_knowledge_response(tool_executions, is_korean)
        else:
            return await self._synthesize_general_response(tool_executions, is_korean)

    async def _synthesize_recommendation_response(self, tool_executions: List[ToolExecution], is_korean: bool) -> str:
        """Synthesize response for recommendation requests."""
        search_results = None

        for execution in tool_executions:
            if execution.tool_name == "hybrid_search" and execution.success:
                search_results = execution.result
                break

        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if is_korean else "Sorry, no search results found."

        if is_korean:
            response = "í–¥ìˆ˜ ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"

            for i, item in enumerate(search_results[:3], 1):
                response += f"{i}. **{item.name}** (by {item.brand})\n"
                response += f"   - ì„¤ëª…: {item.description[:100]}...\n"
                response += f"   - ë§¤ì¹­ ì ìˆ˜: {item.combined_score:.2f}\n\n"

            response += "\nì´ëŸ¬í•œ í–¥ìˆ˜ë“¤ì´ ê·€í•˜ì˜ ì·¨í–¥ì— ë§ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê°ê°ì€ ê³ ìœ í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´ ë‹¤ì–‘í•œ ê²½í—˜ì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤."
        else:
            response = "Here are my perfume recommendations:\n\n"

            for i, item in enumerate(search_results[:3], 1):
                response += f"{i}. **{item.name}** by {item.brand}\n"
                response += f"   - Description: {item.description[:100]}...\n"
                response += f"   - Match Score: {item.combined_score:.2f}\n\n"

            response += "\nThese perfumes should suit your preferences perfectly. Each offers unique characteristics for different experiences."

        return response

    async def _synthesize_creation_response(self, tool_executions: List[ToolExecution], is_korean: bool) -> str:
        """Synthesize response for creation requests using AI."""
        validation_result = None
        search_inspiration = None

        for execution in tool_executions:
            if execution.tool_name == "validate_composition" and execution.success:
                validation_result = execution.result
            elif execution.tool_name == "hybrid_search" and execution.success:
                search_inspiration = execution.result

        # Generate fragrance using AI
        try:
            return await self._generate_fragrance_with_ai(validation_result, search_inspiration, is_korean)
        except Exception as e:
            logger.error(f"AI generation failed: {e}")
            return await self._fallback_creation_response(validation_result, is_korean)

    async def _generate_fragrance_with_ai(self, validation_result, search_inspiration, is_korean: bool) -> str:
        """ì§„ì§œ LLMìœ¼ë¡œ í–¥ìˆ˜ ìƒì„± - ëŒ€í™”í˜• LLM + ë ˆì‹œí”¼ ìƒì„± LLM ì¡°í•©"""
        try:
            # 1ë‹¨ê³„: ëŒ€í™”í˜• LLMìœ¼ë¡œ ê³ ê° ì˜ë„ íŒŒì•…
            conversation_response = await self.conversation_llm.chat(
                self.current_query,
                context={
                    "validation_result": validation_result,
                    "search_inspiration": search_inspiration
                }
            )

            # 2ë‹¨ê³„: í–¥ìˆ˜ ë ˆì‹œí”¼ ìƒì„±ì´ í•„ìš”í•œì§€ íŒë‹¨
            if self._needs_recipe_generation(self.current_query):
                # í–¥ìˆ˜ ìƒì„± LLMìœ¼ë¡œ ì‹¤ì œ ë ˆì‹œí”¼ ìƒì„±
                recipe_result = await self.recipe_generator.generate_recipe(
                    user_requirements=self.current_query,
                    conversation_context=conversation_response,
                    inspiration_data=search_inspiration
                )

                # ë ˆì‹œí”¼ì™€ ëŒ€í™”ë¥¼ í†µí•©í•œ ì‘ë‹µ ìƒì„±
                integrated_response = self._integrate_conversation_and_recipe(
                    conversation_response, recipe_result, is_korean
                )

                # ê´€ë¦¬ì ì£¼ë¬¸ì„œ ìƒì„±
                self._create_and_send_real_order(recipe_result, self.current_query)

                return integrated_response
            else:
                # ë‹¨ìˆœ ëŒ€í™”ë§Œ í•„ìš”í•œ ê²½ìš°
                return conversation_response

        except Exception as e:
            logger.error(f"ì§„ì§œ LLM ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ - ëª©ì—… ì—†ìŒ
            raise Exception("ì‘ë‹µ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")


    async def _fallback_ai_generation(self, validation_result, is_korean: bool) -> str:
        """í´ë°± AI ê¸°ë°˜ í–¥ìˆ˜ ìƒì„± (í•˜ë“œì½”ë”© ë¡œì§ ì™„ì „ ì œê±°)"""
        # í´ë°±ë„ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì²˜ë¦¬ - ëª©ì—… ëŒ€ë‹µ ì—†ìŒ
        raise Exception("ì‘ë‹µ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

    async def _synthesize_knowledge_response(self, tool_executions: List[ToolExecution], is_korean: bool) -> str:
        """Synthesize response for knowledge requests."""
        knowledge_result = None

        for execution in tool_executions:
            if execution.tool_name == "query_knowledge_base" and execution.success:
                knowledge_result = execution.result
                break

        if not knowledge_result:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if is_korean else "Sorry, the requested information could not be found."

        if hasattr(knowledge_result, 'style_characteristics'):
            # Perfumer style response
            if is_korean:
                response = f"ğŸ¨ **{knowledge_result.name}ì˜ ì¡°í–¥ ìŠ¤íƒ€ì¼** ğŸ¨\n\n"
                response += "**ìŠ¤íƒ€ì¼ íŠ¹ì§•:**\n"
                for char in knowledge_result.style_characteristics:
                    response += f"â€¢ {char}\n"

                response += f"\n**ì„ í˜¸ ì¬ë£Œ:**\n"
                for material in knowledge_result.favorite_materials:
                    response += f"â€¢ {material}\n"

                if knowledge_result.philosophy:
                    response += f"\n**ì² í•™:**\n{knowledge_result.philosophy}"
            else:
                response = f"ğŸ¨ **{knowledge_result.name}'s Perfumery Style** ğŸ¨\n\n"
                response += "**Style Characteristics:**\n"
                for char in knowledge_result.style_characteristics:
                    response += f"â€¢ {char}\n"

                response += f"\n**Favorite Materials:**\n"
                for material in knowledge_result.favorite_materials:
                    response += f"â€¢ {material}\n"

                if knowledge_result.philosophy:
                    response += f"\n**Philosophy:**\n{knowledge_result.philosophy}"
        else:
            # Accord formula response
            if is_korean:
                response = f"ğŸ§ª **{knowledge_result.name} ì¡°í™”** ğŸ§ª\n\n"
                response += "**êµ¬ì„± ì„±ë¶„:**\n"
                for ingredient, percentage in knowledge_result.ingredients.items():
                    response += f"â€¢ {ingredient}: {percentage}%\n"

                response += f"\n**í–¥ì¡° íš¨ê³¼:**\n{knowledge_result.olfactory_effect}\n"
                response += f"\n**ì°½ì¡°ì:** {knowledge_result.creator}"
            else:
                response = f"ğŸ§ª **{knowledge_result.name} Accord** ğŸ§ª\n\n"
                response += "**Ingredients:**\n"
                for ingredient, percentage in knowledge_result.ingredients.items():
                    response += f"â€¢ {ingredient}: {percentage}%\n"

                response += f"\n**Olfactory Effect:**\n{knowledge_result.olfactory_effect}\n"
                response += f"\n**Creator:** {knowledge_result.creator}"

        return response

    async def _synthesize_general_response(self, tool_executions: List[ToolExecution], is_korean: bool) -> str:
        """Synthesize response for general inquiries."""
        if is_korean:
            return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Artisan, ë‹¹ì‹ ì˜ AI ì¡°í–¥ì‚¬ì…ë‹ˆë‹¤. í–¥ìˆ˜ ì¶”ì²œ, ìƒˆë¡œìš´ í–¥ìˆ˜ ì°½ì¡°, ë˜ëŠ” í–¥ìˆ˜ì— ëŒ€í•œ ì§€ì‹ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”."
        else:
            return "Hello! I'm Artisan, your AI Perfumer. I can help you with perfume recommendations, create new fragrances, or share knowledge about the art of perfumery. How may I assist you today?"

    def _create_and_send_ai_order(self, ai_response, original_query):
        """AI ìƒì„± í–¥ìˆ˜ ì£¼ë¬¸ ë°ì´í„° ìƒì„± ë° ê´€ë¦¬ì ì„œë²„ ì „ì†¡"""
        try:
            import os

            order_id = f"AI-ORDER-{int(time.time())}"

            # AI ì‘ë‹µì—ì„œ ë ˆì‹œí”¼ ì •ë³´ ì¶”ì¶œ
            if hasattr(ai_response, 'recipe'):
                recipe_data = ai_response.recipe
            else:
                recipe_data = {
                    "concept": "AI ìƒì„± ë§ì¶¤ í–¥ìˆ˜",
                    "top_notes": ai_response.get('top_notes', ['ë² ë¥´ê°€ëª»', 'ë ˆëª¬']),
                    "middle_notes": ai_response.get('middle_notes', ['ì¥ë¯¸', 'ì¬ìŠ¤ë¯¼']),
                    "base_notes": ai_response.get('base_notes', ['ìƒŒë‹¬ìš°ë“œ', 'ë¨¸ìŠ¤í¬']),
                    "ai_generated": True,
                    "quality_score": ai_response.get('quality_score', 0.95)
                }

            order_data = {
                "order_id": order_id,
                "timestamp": datetime.now().isoformat(),
                "customer_request": original_query,
                "recipe": recipe_data,
                "ai_generated": True,
                "generation_method": "Master Perfumer AI",
                "quality_validation": {
                    "harmony_score": ai_response.get('quality_score', 0.95),
                    "innovation_score": ai_response.get('innovation_score', 0.90),
                    "feasibility_score": ai_response.get('feasibility_score', 0.88)
                },
                "estimated_production_time": "5-7ì¼ (AI ìµœì í™” ì ìš©)",
                "notes": f"ë§ˆìŠ¤í„° ì¡°í–¥ì‚¬ AIê°€ ìƒì„±í•œ ê³ í’ˆì§ˆ ë ˆì‹œí”¼ - ê³ ê° ìš”ì²­: {original_query}"
            }

            # ê´€ë¦¬ì ì£¼ë¬¸ì„œ ë””ë ‰í† ë¦¬ ìƒì„±
            admin_dir = "admin_orders"
            if not os.path.exists(admin_dir):
                os.makedirs(admin_dir)

            # ì£¼ë¬¸ì„œ íŒŒì¼ë¡œ ì €ì¥
            order_file = os.path.join(admin_dir, f"{order_id}.json")
            with open(order_file, 'w', encoding='utf-8') as f:
                json.dump(order_data, f, ensure_ascii=False, indent=2)

            logger.info(f"AI ìƒì„± ì£¼ë¬¸ì„œ ì €ì¥ë¨: {order_file}")

        except Exception as e:
            logger.error(f"AI ì£¼ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    def _needs_recipe_generation(self, user_query: str) -> bool:
        """í–¥ìˆ˜ ë ˆì‹œí”¼ ìƒì„±ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        recipe_keywords = [
            "ë§Œë“¤ì–´", "ìƒì„±", "create", "generate", "í–¥ìˆ˜", "perfume", "recipe",
            "ë ˆì‹œí”¼", "ì¡°í–¥", "blend", "fragrance", "ë§Œë“¤", "ì œì‘"
        ]

        query_lower = user_query.lower()
        return any(keyword in query_lower for keyword in recipe_keywords)

    def _integrate_conversation_and_recipe(self, conversation: str, recipe_data: Dict, is_korean: bool) -> str:
        """ëŒ€í™”ì™€ ë ˆì‹œí”¼ë¥¼ í†µí•©í•œ ì‘ë‹µ ìƒì„±"""
        if is_korean:
            response = f"{conversation}\n\n"
            response += "ğŸŒŸ **ë§ì¶¤ í–¥ìˆ˜ ë ˆì‹œí”¼**\n\n"

            if 'top_notes' in recipe_data:
                response += f"â€¢ **íƒ‘ ë…¸íŠ¸**: {', '.join(recipe_data['top_notes'])}\n"
            if 'middle_notes' in recipe_data:
                response += f"â€¢ **ë¯¸ë“¤ ë…¸íŠ¸**: {', '.join(recipe_data['middle_notes'])}\n"
            if 'base_notes' in recipe_data:
                response += f"â€¢ **ë² ì´ìŠ¤ ë…¸íŠ¸**: {', '.join(recipe_data['base_notes'])}\n\n"

            if 'description' in recipe_data:
                response += f"**ì„¤ëª…**: {recipe_data['description']}\n\n"

            response += "ğŸ“‹ ì£¼ë¬¸ì„œê°€ ê´€ë¦¬ìì—ê²Œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            response = f"{conversation}\n\n"
            response += "ğŸŒŸ **Custom Fragrance Recipe**\n\n"

            if 'top_notes' in recipe_data:
                response += f"â€¢ **Top Notes**: {', '.join(recipe_data['top_notes'])}\n"
            if 'middle_notes' in recipe_data:
                response += f"â€¢ **Middle Notes**: {', '.join(recipe_data['middle_notes'])}\n"
            if 'base_notes' in recipe_data:
                response += f"â€¢ **Base Notes**: {', '.join(recipe_data['base_notes'])}\n\n"

            if 'description' in recipe_data:
                response += f"**Description**: {recipe_data['description']}\n\n"

            response += "ğŸ“‹ Order has been sent to the administrator."

        return response

    def _create_and_send_real_order(self, recipe_data: Dict, original_query: str):
        """ì‹¤ì œ LLM ìƒì„± ë ˆì‹œí”¼ ì£¼ë¬¸ì„œ ìƒì„±"""
        try:
            import os

            order_id = f"REAL-LLM-{int(time.time())}"
            order_data = {
                "order_id": order_id,
                "timestamp": datetime.now().isoformat(),
                "customer_request": original_query,
                "recipe": recipe_data,
                "generation_method": "Real LLM System",
                "llm_enhanced": True,
                "conversation_llm": "DialoGPT-medium",
                "recipe_llm": "FragranceRecipeGenerator",
                "estimated_production_time": "3-5ì¼ (LLM ìµœì í™”)",
                "notes": f"ì§„ì§œ LLM ì‹œìŠ¤í…œìœ¼ë¡œ ìƒì„±ëœ ê³ í’ˆì§ˆ ë ˆì‹œí”¼ - ê³ ê° ìš”ì²­: {original_query}"
            }

            # ê´€ë¦¬ì ì£¼ë¬¸ì„œ ë””ë ‰í† ë¦¬ ìƒì„±
            admin_dir = "admin_orders"
            if not os.path.exists(admin_dir):
                os.makedirs(admin_dir)

            # ì£¼ë¬¸ì„œ íŒŒì¼ë¡œ ì €ì¥
            order_file = os.path.join(admin_dir, f"{order_id}.json")
            with open(order_file, 'w', encoding='utf-8') as f:
                json.dump(order_data, f, ensure_ascii=False, indent=2)

            logger.info(f"ì§„ì§œ LLM ì£¼ë¬¸ì„œ ì €ì¥ë¨: {order_file}")

        except Exception as e:
            logger.error(f"ì‹¤ì œ LLM ì£¼ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    async def _fallback_creation_response(self, validation_result, is_korean: bool) -> str:
        """ìµœì¢… í´ë°± ì‘ë‹µ (ëª¨ë“  AIê°€ ì‹¤íŒ¨í–ˆì„ ë•Œ)"""
        # ìµœì¢… í´ë°±ë„ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì²˜ë¦¬ - ëª©ì—… ëŒ€ë‹µ ì—†ìŒ
        raise Exception("ì‘ë‹µ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")