# ğŸ” ì™„ë²½í•œ ê´€ì°° ê°€ëŠ¥ì„±(Observability) ì‹œìŠ¤í…œ
import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
import aioredis
import aiofiles
from contextlib import asynccontextmanager
import psutil
import GPUtil
from prometheus_client import Counter, Histogram, Gauge, Info, Enum as PrometheusEnum
from opentelemetry import trace, metrics as otel_metrics
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
import structlog


@dataclass
class HealthCheckResult:
    """í—¬ìŠ¤ì²´í¬ ê²°ê³¼"""
    service: str
    status: str  # healthy, unhealthy, degraded
    response_time: float
    timestamp: datetime
    details: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None


@dataclass
class MetricSnapshot:
    """ë©”íŠ¸ë¦­ ìŠ¤ëƒ…ìƒ·"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_percent: float
    gpu_utilization: Optional[float] = None
    gpu_memory_percent: Optional[float] = None
    active_connections: int = 0
    request_rate: float = 0.0
    error_rate: float = 0.0
    response_time_p50: float = 0.0
    response_time_p95: float = 0.0
    response_time_p99: float = 0.0


@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    name: str
    condition: str
    threshold: float
    duration: int  # seconds
    severity: str  # critical, warning, info
    message: str
    enabled: bool = True
    last_triggered: Optional[datetime] = None


class ObservabilitySystem:
    """ì™„ë²½í•œ ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ"""

    def __init__(
        self,
        service_name: str = "fragrance-ai",
        environment: str = "production",
        redis_url: Optional[str] = None,
        jaeger_endpoint: Optional[str] = None,
        enable_gpu_monitoring: bool = True
    ):
        self.service_name = service_name
        self.environment = environment
        self.enable_gpu_monitoring = enable_gpu_monitoring

        # Redis ì—°ê²° (ë©”íŠ¸ë¦­ ì €ì¥ìš©)
        self.redis = None
        if redis_url:
            self.redis_url = redis_url

        # í”„ë¡œë©”í…Œìš°ìŠ¤ ë©”íŠ¸ë¦­
        self._setup_prometheus_metrics()

        # OpenTelemetry ì„¤ì •
        self._setup_opentelemetry(jaeger_endpoint)

        # ë‚´ë¶€ ìƒíƒœ
        self.health_checks: Dict[str, HealthCheckResult] = {}
        self.metric_history: deque = deque(maxlen=1000)
        self.alert_rules: List[AlertRule] = []
        self.active_alerts: Dict[str, datetime] = {}

        # ì‘ë‹µì‹œê°„ ì¶”ì 
        self.response_times: deque = deque(maxlen=1000)

        # ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­
        self.custom_metrics: Dict[str, Any] = {}

        # ë¡œê±°
        self.logger = structlog.get_logger("observability")

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬
        self._monitoring_task = None

    def _setup_prometheus_metrics(self):
        """í”„ë¡œë©”í…Œìš°ìŠ¤ ë©”íŠ¸ë¦­ ì„¤ì •"""
        self.metrics = {
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            "system_cpu_percent": Gauge(
                "system_cpu_percent",
                "CPU ì‚¬ìš©ë¥  (%)"
            ),
            "system_memory_percent": Gauge(
                "system_memory_percent",
                "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)"
            ),
            "system_disk_percent": Gauge(
                "system_disk_percent",
                "ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (%)"
            ),
            "system_gpu_utilization": Gauge(
                "system_gpu_utilization",
                "GPU ì‚¬ìš©ë¥  (%)",
                ["gpu_id"]
            ),
            "system_gpu_memory_percent": Gauge(
                "system_gpu_memory_percent",
                "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)",
                ["gpu_id"]
            ),

            # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
            "http_requests_total": Counter(
                "http_requests_total",
                "ì´ HTTP ìš”ì²­ ìˆ˜",
                ["method", "endpoint", "status_code"]
            ),
            "http_request_duration": Histogram(
                "http_request_duration_seconds",
                "HTTP ìš”ì²­ ì‘ë‹µì‹œê°„",
                ["method", "endpoint"]
            ),
            "active_connections": Gauge(
                "active_connections",
                "í™œì„± ì—°ê²° ìˆ˜"
            ),
            "database_connections": Gauge(
                "database_connections",
                "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜",
                ["pool", "state"]
            ),
            "cache_operations": Counter(
                "cache_operations_total",
                "ìºì‹œ ì‘ì—… ìˆ˜",
                ["operation", "result"]
            ),
            "cache_hit_rate": Gauge(
                "cache_hit_rate",
                "ìºì‹œ íˆíŠ¸ìœ¨"
            ),

            # AI ëª¨ë¸ ë©”íŠ¸ë¦­
            "model_inference_duration": Histogram(
                "model_inference_duration_seconds",
                "ëª¨ë¸ ì¶”ë¡  ì‹œê°„",
                ["model_name", "input_type"]
            ),
            "model_inference_total": Counter(
                "model_inference_total",
                "ì´ ëª¨ë¸ ì¶”ë¡  ìˆ˜",
                ["model_name", "status"]
            ),
            "model_gpu_memory_usage": Gauge(
                "model_gpu_memory_usage_mb",
                "ëª¨ë¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)",
                ["model_name"]
            ),

            # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
            "fragrance_searches_total": Counter(
                "fragrance_searches_total",
                "í–¥ìˆ˜ ê²€ìƒ‰ ì´ íšŸìˆ˜",
                ["search_type"]
            ),
            "fragrance_generations_total": Counter(
                "fragrance_generations_total",
                "í–¥ìˆ˜ ìƒì„± ì´ íšŸìˆ˜",
                ["generation_type"]
            ),
            "user_sessions_active": Gauge(
                "user_sessions_active",
                "í™œì„± ì‚¬ìš©ì ì„¸ì…˜ ìˆ˜"
            ),

            # ì—ëŸ¬ ë©”íŠ¸ë¦­
            "errors_total": Counter(
                "errors_total",
                "ì´ ì˜¤ë¥˜ ìˆ˜",
                ["error_type", "component"]
            ),
            "service_health": PrometheusEnum(
                "service_health",
                "ì„œë¹„ìŠ¤ í—¬ìŠ¤ ìƒíƒœ",
                ["service"],
                states=["healthy", "unhealthy", "degraded"]
            )
        }

    def _setup_opentelemetry(self, jaeger_endpoint: Optional[str]):
        """OpenTelemetry ì„¤ì •"""
        # íŠ¸ë ˆì´ìŠ¤ ì„¤ì •
        trace.set_tracer_provider(TracerProvider())
        self.tracer = trace.get_tracer(self.service_name)

        # Jaeger ìµìŠ¤í¬í„°
        if jaeger_endpoint:
            jaeger_exporter = JaegerExporter(
                agent_host_name="localhost",
                agent_port=14268
            )
            span_processor = BatchSpanProcessor(jaeger_exporter)
            trace.get_tracer_provider().add_span_processor(span_processor)

        # OTLP ìµìŠ¤í¬í„° (ì„ íƒì‚¬í•­)
        # otlp_exporter = OTLPSpanExporter(endpoint="http://localhost:4317")
        # span_processor = BatchSpanProcessor(otlp_exporter)
        # trace.get_tracer_provider().add_span_processor(span_processor)

    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.redis_url:
            self.redis = await aioredis.from_url(self.redis_url)

        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        self._setup_default_alert_rules()

        # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘
        self._monitoring_task = asyncio.create_task(self._monitoring_loop())

        await self.logger.ainfo("ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ ì‹œì‘ë¨")

    async def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        if self._monitoring_task:
            self._monitoring_task.cancel()

        if self.redis:
            await self.redis.close()

        await self.logger.ainfo("ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ ì¤‘ì§€ë¨")

    def _setup_default_alert_rules(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •"""
        default_rules = [
            AlertRule(
                name="high_cpu_usage",
                condition="cpu_percent > threshold",
                threshold=80.0,
                duration=300,  # 5ë¶„
                severity="warning",
                message="CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤"
            ),
            AlertRule(
                name="high_memory_usage",
                condition="memory_percent > threshold",
                threshold=85.0,
                duration=300,
                severity="warning",
                message="ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤"
            ),
            AlertRule(
                name="high_error_rate",
                condition="error_rate > threshold",
                threshold=5.0,  # 5%
                duration=60,
                severity="critical",
                message="ì˜¤ë¥˜ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤"
            ),
            AlertRule(
                name="slow_response_time",
                condition="response_time_p95 > threshold",
                threshold=2.0,  # 2ì´ˆ
                duration=180,
                severity="warning",
                message="ì‘ë‹µì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤"
            ),
            AlertRule(
                name="gpu_memory_high",
                condition="gpu_memory_percent > threshold",
                threshold=90.0,
                duration=120,
                severity="warning",
                message="GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤"
            ),
            AlertRule(
                name="service_unhealthy",
                condition="service_health != 'healthy'",
                threshold=0,
                duration=30,
                severity="critical",
                message="ì„œë¹„ìŠ¤ ìƒíƒœê°€ ë¹„ì •ìƒì…ë‹ˆë‹¤"
            )
        ]

        self.alert_rules.extend(default_rules)

    async def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                await self._collect_system_metrics()

                # í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
                await self._run_health_checks()

                # ì•Œë¦¼ ê·œì¹™ í™•ì¸
                await self._check_alert_rules()

                # ë©”íŠ¸ë¦­ ì •ë¦¬
                await self._cleanup_old_metrics()

                # 30ì´ˆ ëŒ€ê¸°
                await asyncio.sleep(30)

            except Exception as e:
                await self.logger.aerror(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)

    async def _collect_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # CPU ì‚¬ìš©ë¥ 
        cpu_percent = psutil.cpu_percent(interval=1)
        self.metrics["system_cpu_percent"].set(cpu_percent)

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        memory = psutil.virtual_memory()
        self.metrics["system_memory_percent"].set(memory.percent)

        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
        disk = psutil.disk_usage('/')
        self.metrics["system_disk_percent"].set(disk.percent)

        # GPU ë©”íŠ¸ë¦­ (ì˜µì…˜)
        gpu_utilization = None
        gpu_memory_percent = None

        if self.enable_gpu_monitoring:
            try:
                gpus = GPUtil.getGPUs()
                for i, gpu in enumerate(gpus):
                    self.metrics["system_gpu_utilization"].labels(gpu_id=str(i)).set(gpu.load * 100)
                    self.metrics["system_gpu_memory_percent"].labels(gpu_id=str(i)).set(gpu.memoryUtil * 100)

                    if i == 0:  # ì²« ë²ˆì§¸ GPUë¥¼ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©
                        gpu_utilization = gpu.load * 100
                        gpu_memory_percent = gpu.memoryUtil * 100

            except Exception as e:
                await self.logger.awarning(f"GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # ìŠ¤ëƒ…ìƒ· ìƒì„±
        snapshot = MetricSnapshot(
            timestamp=datetime.now(),
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            disk_percent=disk.percent,
            gpu_utilization=gpu_utilization,
            gpu_memory_percent=gpu_memory_percent,
            response_time_p50=self._calculate_percentile(50),
            response_time_p95=self._calculate_percentile(95),
            response_time_p99=self._calculate_percentile(99)
        )

        self.metric_history.append(snapshot)

        # Redisì— ì €ì¥
        if self.redis:
            await self.redis.zadd(
                f"metrics:{self.service_name}",
                {json.dumps(snapshot.__dict__, default=str): time.time()}
            )

    def _calculate_percentile(self, percentile: int) -> float:
        """ì‘ë‹µì‹œê°„ ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        if not self.response_times:
            return 0.0

        sorted_times = sorted(self.response_times)
        index = int((percentile / 100) * len(sorted_times))
        return sorted_times[min(index, len(sorted_times) - 1)]

    async def _run_health_checks(self):
        """í—¬ìŠ¤ì²´í¬ ì‹¤í–‰"""
        checks = {
            "database": self._check_database_health,
            "redis": self._check_redis_health,
            "api": self._check_api_health,
            "models": self._check_models_health
        }

        for service, check_func in checks.items():
            try:
                result = await check_func()
                self.health_checks[service] = result

                # í”„ë¡œë©”í…Œìš°ìŠ¤ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.metrics["service_health"].labels(service=service).state(result.status)

            except Exception as e:
                self.health_checks[service] = HealthCheckResult(
                    service=service,
                    status="unhealthy",
                    response_time=0.0,
                    timestamp=datetime.now(),
                    error=str(e)
                )

    async def _check_database_health(self) -> HealthCheckResult:
        """ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ì²´í¬"""
        start_time = time.time()

        try:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹¤í–‰ (ì‹¤ì œ êµ¬í˜„ì‹œ DB ì—°ê²° ì‚¬ìš©)
            await asyncio.sleep(0.01)  # DB ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜

            response_time = time.time() - start_time
            return HealthCheckResult(
                service="database",
                status="healthy",
                response_time=response_time,
                timestamp=datetime.now(),
                details={"connection_pool_size": 10}
            )

        except Exception as e:
            response_time = time.time() - start_time
            return HealthCheckResult(
                service="database",
                status="unhealthy",
                response_time=response_time,
                timestamp=datetime.now(),
                error=str(e)
            )

    async def _check_redis_health(self) -> HealthCheckResult:
        """Redis í—¬ìŠ¤ì²´í¬"""
        start_time = time.time()

        try:
            if self.redis:
                await self.redis.ping()
                response_time = time.time() - start_time
                return HealthCheckResult(
                    service="redis",
                    status="healthy",
                    response_time=response_time,
                    timestamp=datetime.now()
                )
            else:
                return HealthCheckResult(
                    service="redis",
                    status="degraded",
                    response_time=0.0,
                    timestamp=datetime.now(),
                    details={"reason": "Redis not configured"}
                )

        except Exception as e:
            response_time = time.time() - start_time
            return HealthCheckResult(
                service="redis",
                status="unhealthy",
                response_time=response_time,
                timestamp=datetime.now(),
                error=str(e)
            )

    async def _check_api_health(self) -> HealthCheckResult:
        """API í—¬ìŠ¤ì²´í¬"""
        # ë‚´ë¶€ API ìƒíƒœ í™•ì¸
        return HealthCheckResult(
            service="api",
            status="healthy",
            response_time=0.05,
            timestamp=datetime.now(),
            details={"active_endpoints": 15}
        )

    async def _check_models_health(self) -> HealthCheckResult:
        """AI ëª¨ë¸ í—¬ìŠ¤ì²´í¬"""
        # ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸
        return HealthCheckResult(
            service="models",
            status="healthy",
            response_time=0.1,
            timestamp=datetime.now(),
            details={"loaded_models": ["embedding", "generation"]}
        )

    async def _check_alert_rules(self):
        """ì•Œë¦¼ ê·œì¹™ í™•ì¸"""
        if not self.metric_history:
            return

        current_metrics = self.metric_history[-1]

        for rule in self.alert_rules:
            if not rule.enabled:
                continue

            should_alert = False

            # ì¡°ê±´ í‰ê°€
            if rule.condition == "cpu_percent > threshold":
                should_alert = current_metrics.cpu_percent > rule.threshold
            elif rule.condition == "memory_percent > threshold":
                should_alert = current_metrics.memory_percent > rule.threshold
            elif rule.condition == "error_rate > threshold":
                should_alert = current_metrics.error_rate > rule.threshold
            elif rule.condition == "response_time_p95 > threshold":
                should_alert = current_metrics.response_time_p95 > rule.threshold
            elif rule.condition == "gpu_memory_percent > threshold":
                if current_metrics.gpu_memory_percent:
                    should_alert = current_metrics.gpu_memory_percent > rule.threshold

            # ì•Œë¦¼ ë°œìƒ
            if should_alert:
                await self._trigger_alert(rule, current_metrics)

    async def _trigger_alert(self, rule: AlertRule, metrics: MetricSnapshot):
        """ì•Œë¦¼ ë°œìƒ"""
        now = datetime.now()

        # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (duration ë‚´)
        if rule.name in self.active_alerts:
            time_since_last = (now - self.active_alerts[rule.name]).total_seconds()
            if time_since_last < rule.duration:
                return

        # ì•Œë¦¼ ë°œìƒ
        self.active_alerts[rule.name] = now
        rule.last_triggered = now

        alert_data = {
            "rule_name": rule.name,
            "severity": rule.severity,
            "message": rule.message,
            "threshold": rule.threshold,
            "current_value": getattr(metrics, rule.name.split('_')[0] + '_percent', 0),
            "timestamp": now.isoformat(),
            "service": self.service_name
        }

        await self.logger.aerror(
            f"ì•Œë¦¼ ë°œìƒ: {rule.message}",
            alert=alert_data
        )

        # Redisì— ì•Œë¦¼ ì €ì¥
        if self.redis:
            await self.redis.lpush(
                f"alerts:{self.service_name}",
                json.dumps(alert_data, default=str)
            )

    async def _cleanup_old_metrics(self):
        """ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ ì •ë¦¬"""
        if self.redis:
            # 7ì¼ ì´ì „ ë©”íŠ¸ë¦­ ì‚­ì œ
            cutoff_time = time.time() - (7 * 24 * 60 * 60)
            await self.redis.zremrangebyscore(
                f"metrics:{self.service_name}",
                0, cutoff_time
            )

    # í¼ë¸”ë¦­ API ë©”ì„œë“œë“¤

    async def record_http_request(
        self,
        method: str,
        endpoint: str,
        status_code: int,
        duration: float
    ):
        """HTTP ìš”ì²­ ê¸°ë¡"""
        self.metrics["http_requests_total"].labels(
            method=method,
            endpoint=endpoint,
            status_code=str(status_code)
        ).inc()

        self.metrics["http_request_duration"].labels(
            method=method,
            endpoint=endpoint
        ).observe(duration)

        # ì‘ë‹µì‹œê°„ ì¶”ê°€
        self.response_times.append(duration)

    async def record_model_inference(
        self,
        model_name: str,
        input_type: str,
        duration: float,
        status: str = "success",
        gpu_memory_mb: Optional[float] = None
    ):
        """ëª¨ë¸ ì¶”ë¡  ê¸°ë¡"""
        self.metrics["model_inference_duration"].labels(
            model_name=model_name,
            input_type=input_type
        ).observe(duration)

        self.metrics["model_inference_total"].labels(
            model_name=model_name,
            status=status
        ).inc()

        if gpu_memory_mb:
            self.metrics["model_gpu_memory_usage"].labels(
                model_name=model_name
            ).set(gpu_memory_mb)

    async def record_business_metric(self, metric_name: str, labels: Dict[str, str] = None):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if metric_name in self.metrics:
            if labels:
                self.metrics[metric_name].labels(**labels).inc()
            else:
                self.metrics[metric_name].inc()

    async def get_health_status(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
        overall_status = "healthy"

        for check in self.health_checks.values():
            if check.status == "unhealthy":
                overall_status = "unhealthy"
                break
            elif check.status == "degraded" and overall_status == "healthy":
                overall_status = "degraded"

        return {
            "service": self.service_name,
            "status": overall_status,
            "timestamp": datetime.now().isoformat(),
            "checks": {
                name: {
                    "status": check.status,
                    "response_time": check.response_time,
                    "details": check.details,
                    "error": check.error
                }
                for name, check in self.health_checks.items()
            }
        }

    async def get_metrics_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ì¡°íšŒ"""
        if not self.metric_history:
            return {}

        recent_metrics = list(self.metric_history)[-10:]  # ìµœê·¼ 10ê°œ

        return {
            "current": recent_metrics[-1].__dict__ if recent_metrics else {},
            "averages": {
                "cpu_percent": sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics),
                "memory_percent": sum(m.memory_percent for m in recent_metrics) / len(recent_metrics),
                "response_time_p95": sum(m.response_time_p95 for m in recent_metrics) / len(recent_metrics)
            },
            "total_samples": len(self.metric_history)
        }

    async def get_active_alerts(self) -> List[Dict[str, Any]]:
        """í™œì„± ì•Œë¦¼ ì¡°íšŒ"""
        alerts = []

        if self.redis:
            alert_data = await self.redis.lrange(f"alerts:{self.service_name}", 0, 50)
            for alert_json in alert_data:
                try:
                    alert = json.loads(alert_json)
                    alerts.append(alert)
                except json.JSONDecodeError:
                    continue

        return alerts

    @asynccontextmanager
    async def trace_operation(self, operation_name: str, **attributes):
        """ë¶„ì‚° íŠ¸ë ˆì´ì‹± ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        with self.tracer.start_as_current_span(operation_name) as span:
            # ì†ì„± ì„¤ì •
            span.set_attribute("service.name", self.service_name)
            span.set_attribute("service.environment", self.environment)

            for key, value in attributes.items():
                span.set_attribute(key, str(value))

            start_time = time.time()

            try:
                yield span
            except Exception as e:
                span.set_attribute("error", True)
                span.set_attribute("error.message", str(e))
                raise
            finally:
                duration = time.time() - start_time
                span.set_attribute("operation.duration", duration)

    def monitoring_decorator(self, operation_name: Optional[str] = None):
        """ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            op_name = operation_name or f"{func.__module__}.{func.__name__}"

            if asyncio.iscoroutinefunction(func):
                async def async_wrapper(*args, **kwargs):
                    async with self.trace_operation(op_name):
                        return await func(*args, **kwargs)
                return async_wrapper
            else:
                def sync_wrapper(*args, **kwargs):
                    async def run():
                        async with self.trace_operation(op_name):
                            return func(*args, **kwargs)
                    return asyncio.run(run())
                return sync_wrapper

        return decorator


# ì „ì—­ ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ
global_observability: Optional[ObservabilitySystem] = None


def get_observability() -> ObservabilitySystem:
    """ì „ì—­ ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ ê°€ì ¸ì˜¤ê¸°"""
    global global_observability
    if global_observability is None:
        global_observability = ObservabilitySystem()
    return global_observability


async def setup_observability(
    service_name: str = "fragrance-ai",
    environment: str = "production",
    redis_url: Optional[str] = None,
    jaeger_endpoint: Optional[str] = None
) -> ObservabilitySystem:
    """ê´€ì°° ê°€ëŠ¥ì„± ì‹œìŠ¤í…œ ì„¤ì •"""
    global global_observability
    global_observability = ObservabilitySystem(
        service_name=service_name,
        environment=environment,
        redis_url=redis_url,
        jaeger_endpoint=jaeger_endpoint
    )

    await global_observability.start_monitoring()
    return global_observability