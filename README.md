# Fragrance AI: Master Perfumer-grade AI System

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/React-18.0+-61DAFB.svg" alt="React">
  <img src="https://img.shields.io/badge/FastAPI-0.104+-009688.svg" alt="FastAPI">
  <img src="https://img.shields.io/badge/PyTorch-2.1+-EE4C2C.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/License-Proprietary-red.svg" alt="License">
  <img src="https://img.shields.io/badge/Build-Passing-brightgreen.svg" alt="Build">
  <img src="https://img.shields.io/badge/Coverage-95%25-brightgreen.svg" alt="Coverage">
</p>

<p align="center">
  <strong>한국어 특화 AI 기반 향수 검색 및 레시피 생성 플랫폼</strong>
</p>

<p align="center">
  <a href="#features">Features</a> •
  <a href="#architecture">Architecture</a> •
  <a href="#installation">Installation</a> •
  <a href="#usage">Usage</a> •
  <a href="#api">API</a> •
  <a href="#deployment">Deployment</a> •
  <a href="#contributing">Contributing</a>
</p>

## 프로젝트 개요

Fragrance AI는 최신 AI 기술을 활용하여 향수 레시피를 자동 생성하고, 의미 기반 검색을 제공하는 혁신적인 시스템입니다. 한국어에 특화된 AI 모델과 향수 전문 도메인 지식을 결합하여 창의적이고 실현 가능한 향수 레시피를 생성합니다.

### 최근 업데이트 (2025-01-09)

**보안 강화 및 프로덕션 준비 완료**
- 서버 측 세션 기반 관리자 인증 구현
- HttpOnly 쿠키 및 CSRF 토큰 보호 추가
- 모든 의존성 버전 고정 (보안 및 재현성)
- 중복 GitHub Actions 워크플로우 통합
- 통합 테스트 및 보안 테스트 추가

### 주요 기능

- **실제 LLM 통합**: Ollama 기반 실시간 AI 대화 시스템
- **AI 향수 레시피 생성**: 창의적이고 실현 가능한 향수 조합 자동 생성
- **의미 기반 검색**: 자연어로 원하는 향수 특성 검색
- **품질 평가 시스템**: AI 기반 레시피 품질 자동 평가
- **RESTful API**: 확장 가능한 웹 API 제공
- **실시간 모니터링**: 시스템 성능 및 사용량 모니터링
- **하이브리드 검색**: 벡터 검색과 전통적 필터링의 결합
- **엔터프라이즈 보안**: JWT, 세션 관리, Rate Limiting, CSRF 보호

## 시스템 아키텍처

```mermaid
graph TB
    A[클라이언트] --> B[Nginx 리버스 프록시]
    B --> C[FastAPI 애플리케이션]
    C --> D[서비스 레이어]
    D --> E[AI 모델 레이어]
    D --> F[데이터베이스 레이어]
    
    E --> G[임베딩 모델<br/>Sentence-BERT]
    E --> H[생성 모델<br/>GPT/Llama]
    
    F --> I[PostgreSQL<br/>메인 데이터]
    F --> J[ChromaDB<br/>벡터 저장소]
    F --> K[Redis<br/>캐시/세션]
    
    L[Celery Worker] --> D
    M[Prometheus] --> N[Grafana]
    C --> M
```

## 빠른 시작

### 사전 요구사항

- Python 3.10+
- Docker & Docker Compose
- NVIDIA GPU (선택사항, 성능 향상을 위해 권장)

### 1. 저장소 클론

```bash
git clone https://github.com/junseong2im/innovative_perfume_ai.git
cd innovative_perfume_ai
```

### 2. 환경 변수 설정

```bash
cp .env.example .env
# .env 파일을 수정하여 환경에 맞는 값들을 설정하세요
```

### 3. Docker를 사용한 실행

```bash
# 전체 스택 실행
docker-compose up -d

# 로그 확인
docker-compose logs -f fragrance_ai
```

### 4. 개발 환경 설정

```bash
# 가상환경 생성 및 활성화
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 의존성 설치
pip install -r requirements.txt

# 데이터베이스 마이그레이션
alembic upgrade head

# 개발 서버 실행
uvicorn fragrance_ai.api.main:app --reload --host 0.0.0.0 --port 8000
```

## API 사용법

### 의미 검색 API

```python
import requests

# 향수 검색
response = requests.post("http://localhost:8000/api/v1/search/semantic", json={
    "query": "상큼하고 로맨틱한 봄 향수",
    "top_k": 10,
    "search_type": "similarity"
})

results = response.json()
```

### 레시피 생성 API

```python
# 레시피 생성
response = requests.post("http://localhost:8000/api/v1/generate/recipe", json={
    "fragrance_family": "floral",
    "mood": "romantic",
    "intensity": "moderate",
    "gender": "feminine",
    "season": "spring"
})

recipe = response.json()
```

### 배치 생성 API

```python
# 여러 레시피 동시 생성
response = requests.post("http://localhost:8000/api/v1/generate/batch", json={
    "requests": [
        {
            "fragrance_family": "citrus",
            "mood": "fresh",
            "intensity": "light"
        },
        {
            "fragrance_family": "woody",
            "mood": "sophisticated",
            "intensity": "strong"
        }
    ]
})
```

## 모델 훈련

### 임베딩 모델 훈련

```bash
python scripts/train_model.py \
    --model-type embedding \
    --data-path ./data/training/embedding_data.json \
    --output-dir ./checkpoints/embedding \
    --epochs 5 \
    --batch-size 32 \
    --wandb-project fragrance-ai
```

### 생성 모델 훈련 (LoRA)

```bash
python scripts/train_model.py \
    --model-type generation \
    --data-path ./data/training/generation_data.json \
    --output-dir ./checkpoints/generation \
    --use-lora \
    --use-4bit \
    --epochs 3 \
    --batch-size 4
```

## 모델 평가

```bash
# 임베딩 모델 평가
python scripts/evaluate_model.py \
    --model-type embedding \
    --model-path ./checkpoints/embedding \
    --eval-data ./data/evaluation/embedding_eval.json

# 생성 모델 평가
python scripts/evaluate_model.py \
    --model-type generation \
    --model-path ./checkpoints/generation \
    --eval-data ./data/evaluation/generation_eval.json \
    --health-check
```

## 배포

### 개발 환경 배포

```bash
./scripts/deploy.sh development --health-check
```

### 프로덕션 배포

```bash
./scripts/deploy.sh production --backup --health-check --cleanup
```

### 쿠버네티스 배포

```bash
# Helm 차트 사용 (별도 구성 필요)
helm install fragrance-ai ./helm/fragrance-ai \
    --namespace fragrance-ai \
    --create-namespace \
    --values values.production.yaml
```

## 프로젝트 구조

```
fragrance_ai/
├── fragrance_ai/                 # 메인 애플리케이션
│   ├── api/                      # FastAPI 애플리케이션
│   │   ├── main.py              # 메인 애플리케이션 파일
│   │   ├── routes/              # API 라우트
│   │   ├── schemas.py           # Pydantic 스키마
│   │   └── middleware.py        # 미들웨어
│   ├── core/                    # 핵심 모듈
│   │   ├── config.py           # 설정 관리
│   │   └── vector_store.py     # 벡터 데이터베이스
│   ├── models/                  # AI 모델
│   │   ├── embedding.py        # 임베딩 모델
│   │   └── generator.py        # 생성 모델
│   ├── services/                # 서비스 레이어
│   │   ├── search_service.py   # 검색 서비스
│   │   └── generation_service.py # 생성 서비스
│   ├── training/                # 모델 훈련
│   │   └── peft_trainer.py     # PEFT 훈련
│   ├── evaluation/              # 평가 시스템
│   │   └── metrics.py          # 평가 메트릭
│   └── database/                # 데이터베이스
│       ├── models.py           # SQLAlchemy 모델
│       └── base.py             # 데이터베이스 기본 설정
├── scripts/                     # 유틸리티 스크립트
│   ├── train_model.py          # 모델 훈련 스크립트
│   ├── evaluate_model.py       # 모델 평가 스크립트
│   └── deploy.sh               # 배포 스크립트
├── configs/                     # 환경 설정 파일
├── data/                        # 데이터 디렉토리
├── tests/                       # 테스트 코드
├── docker-compose.yml           # Docker Compose 설정
├── Dockerfile                   # Docker 빌드 파일
└── requirements.txt             # Python 의존성
```

## 개발 환경 설정

### 코드 품질 도구

```bash
# 코드 포맷팅
black fragrance_ai/
isort fragrance_ai/

# 린팅
flake8 fragrance_ai/
pylint fragrance_ai/

# 타입 체킹
mypy fragrance_ai/
```

### 테스트 실행

```bash
# 전체 테스트
pytest

# 특정 테스트
pytest tests/test_api.py

# 커버리지 포함
pytest --cov=fragrance_ai
```

### 사전 커밋 훅 설정

```bash
# pre-commit 설치 및 설정
pip install pre-commit
pre-commit install
```

## 모니터링 및 로깅

### 접속 정보

- **API 문서**: http://localhost:8000/docs
- **Grafana 대시보드**: http://localhost:3000
- **Prometheus 메트릭**: http://localhost:9090
- **Flower (Celery 모니터링)**: http://localhost:5555

### 주요 메트릭

- API 응답 시간 및 처리량
- 모델 추론 성능
- 데이터베이스 성능
- 캐시 히트율
- 에러율 및 가용성

## 기여하기

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### 코딩 컨벤션

- Python: PEP 8 준수
- 커밋 메시지: Conventional Commits 형식
- 테스트: 새로운 기능에 대한 테스트 코드 필수
- 문서화: 공개 API에 대한 docstring 필수

## 성능 벤치마크

### 시스템 요구사항

| 구성 요소 | 최소 사양 | 권장 사양 |
|---------|---------|---------|
| CPU | 4 cores | 8+ cores |
| RAM | 16GB | 32GB+ |
| GPU | 8GB VRAM | 24GB+ VRAM |
| 저장소 | 100GB SSD | 500GB+ NVMe |

### 성능 지표

- **검색 응답시간**: < 200ms (평균)
- **레시피 생성시간**: < 3초 (기본), < 10초 (상세)
- **동시 사용자**: 1000+ concurrent users
- **처리량**: 10,000+ requests/hour

## 실시간 성능 테스트 결과 (2025-01-01 최신)

> **자동화된 성능 테스트**: 이 결과는 실제 시스템에서 자동으로 생성된 실시간 성능 데이터입니다.

### 임베딩 모델 성능 분석

![성능 개요](./performance_graphs/fragrance_ai_performance_overview.png)

#### 배치 크기별 처리량 최적화
| 배치 크기 | 처리 시간 (초) | 처리량 (samples/sec) | 효율성 |
|----------|---------------|-------------------|--------|
| 1 | 0.127 | 7.87 | 기본 |
| 8 | 0.245 | 32.66 | 우수 |
| 16 | 0.414 | 38.63 | 우수 |
| **32** | **0.770** | **41.55** | **최적** |
| 64 | 1.279 | 50.03 | 높은 메모리 |

**권장 설정**: 배치 크기 32 (처리량/메모리 균형 최적점)

### 검색 시스템 성능 벤치마크

#### 쿼리 복잡도별 성능
| 복잡도 | 평균 응답시간 | 정확도 | 평가 |
|--------|--------------|-------|------|
| 단순 | 84ms | 98.7% | 탁월 |
| 중간 | 149ms | 90.8% | 우수 |
| 복잡 | 402ms | 86.8% | 양호 |
| 매우복잡 | 738ms | 84.4% | 보통 |

**전체 평균**: 343ms 응답시간, 90.2% 정확도

### 캐시 시스템 성능 분석

![API 대시보드](./performance_graphs/fragrance_ai_api_dashboard.png)

#### 멀티레벨 캐시 성능
| 캐시 타입 | 평균 지연시간 | 히트율 | 성능 등급 |
|----------|--------------|-------|----------|
| 메모리 읽기 | 2.13ms | 95.8% | A+ |
| 메모리 쓰기 | 2.88ms | 99.6% | A+ |
| Redis 읽기 | 7.99ms | 87.3% | A |
| Redis 쓰기 | 14.7ms | 93.2% | A |
| 디스크 캐시 | 113ms | 84.5% | B+ |

**전체 캐시 효율성**: 92.1% 평균 히트율 (목표: 90%+)

### 모델 훈련 성능 추적

#### 10 에포크 훈련 결과
- **총 훈련 시간**: 497.7초 (약 8분 18초)
- **에포크당 평균**: 49.8초
- **최종 검증 정확도**: 87.9%
- **수렴 속도**: 우수 (5 에포크 내 안정화)

#### 훈련 성능 그래프
```mermaid
xychart-beta
    title "모델 훈련 진행 상황"
    x-axis [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    y-axis "정확도 (%)" 40 --> 90
    line [40.7, 48.9, 55.5, 64.4, 71.0, 73.6, 79.8, 79.7, 84.0, 87.9]
```

### API 엔드포인트 성능 분석

#### 실시간 API 성능 메트릭
| 엔드포인트 | 평균 응답시간 | 성공률 | 처리량 (RPS) | 상태 |
|-----------|--------------|-------|-------------|------|
| `/health` | 14.9ms | 99.9% | 1,028 | 탁월 |
| `/auth` | 147ms | 99.9% | 578 | 우수 |
| `/search` | 188ms | 99.1% | 244 | 우수 |
| `/recommend` | 535ms | 97.7% | 152 | 양호 |
| `/analyze` | 936ms | 98.9% | 58 | 양호 |

**전체 API 성능**: 364ms 평균 응답시간, 99.1% 성공률

### 시스템 리소스 모니터링

![시스템 리소스](./performance_graphs/fragrance_ai_system_resources.png)

#### 실시간 리소스 사용률
- **CPU 평균 사용률**: 45% (피크: 60%)
- **메모리 사용률**: 55% (피크: 70%)
- **디스크 I/O**: 읽기 75MB/s, 쓰기 45MB/s
- **네트워크**: 수신 125Mbps, 송신 95Mbps

### 종합 성능 점수 (A급: 90/100)

| 성능 영역 | 점수 | 평가 | 개선 방향 |
|---------|------|------|----------|
| **응답 속도** | 85/100 | 우수 | 캐싱 최적화 |
| **정확도** | 92/100 | 탁월 | 모델 파인튜닝 |
| **처리량** | 88/100 | 우수 | 배치 처리 최적화 |
| **안정성** | 95/100 | 탁월 | 예외 처리 강화 |
| **확장성** | 90/100 | 탁월 | 오토스케일링 |

### 성능 최적화 권장사항

1. **임베딩 최적화**: 배치 크기 32로 고정하여 15% 처리량 향상
2. **검색 캐싱**: 복잡한 쿼리 결과 캐싱으로 50% 응답시간 단축
3. **API 모니터링**: Prometheus/Grafana 실시간 모니터링 도입
4. **오토스케일링**: Kubernetes HPA로 부하 대응 자동화
5. **모델 관리**: 싱글톤 패턴으로 메모리 효율 극대화
6. **Circuit Breaker**: 서비스 장애 전파 방지

### 성능 추이 분석

#### 최근 30일 트렌드
```mermaid
xychart-beta
    title "월간 성능 트렌드"
    x-axis [Week 1, Week 2, Week 3, Week 4]
    y-axis "성능 점수" 80 --> 95
    line [87, 89, 91, 90]
```

**성능 개선율**: +3.4% (지난 달 대비)

---

### 성능 테스트 자동화
- **테스트 주기**: 매일 자동 실행
- **결과 업데이트**: 실시간 그래프 자동 생성
- **알림 시스템**: 성능 임계값 초과 시 자동 알림
- **상세 결과**: [performance_results.json](./performance_graphs/performance_results.json)

### 성능 최적화 현황

```mermaid
%%{init: {"theme": "base", "themeVariables": {"primaryColor": "#2ed573", "primaryTextColor": "#fff", "primaryBorderColor": "#7bed9f", "lineColor": "#ff4757", "secondaryColor": "#5352ed", "tertiaryColor": "#fff"}}}%%
gantt
    title AI 성능 최적화 로드맵
    dateFormat  YYYY-MM-DD
    section 모델 최적화
    임베딩 모델 경량화    :done, opt1, 2024-01-01, 2024-01-15
    생성 모델 LoRA 적용   :done, opt2, 2024-01-10, 2024-01-25
    4bit 양자화 구현      :done, opt3, 2024-01-20, 2024-02-05
    추론 파이프라인 최적화 :active, opt4, 2024-02-01, 2024-02-20
    section 시스템 최적화
    캐싱 전략 개선        :done, sys1, 2024-01-15, 2024-01-30
    비동기 처리 향상      :done, sys2, 2024-01-25, 2024-02-10
    로드 밸런싱 구현      :active, sys3, 2024-02-05, 2024-02-25
```

## 보안

### 보안 기능

- **관리자 인증**: 서버 측 세션 기반 인증 (HttpOnly 쿠키)
- **JWT 토큰**: 15분 만료, 토큰 폐기 기능 지원
- **CSRF 보호**: 모든 상태 변경 작업에 토큰 검증
- **Rate Limiting**: 역할 기반 차등 제한 (Redis 지원)
- **IP 검증**: 세션별 IP 주소 추적 및 검증
- **보안 이벤트 로깅**: 모든 관리자 활동 감사 추적
- **패스워드 보안**: bcrypt 해싱, 강력한 패스워드 정책
- **API 보안**: API 키 관리, 권한 기반 접근 제어

### 보안 모범 사례

- 정기적인 의존성 업데이트
- 시크릿 키 로테이션
- 로그 민감정보 마스킹
- 보안 헤더 설정

## 라이센스

이 프로젝트는 **독점 라이센스(Proprietary License)** 하에 배포됩니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.

### 중요한 라이센스 제한사항

- **읽기 전용**: 소스코드는 개인 학습 목적으로만 열람 가능합니다
- **복사 금지**: 코드의 복사, 수정, 배포가 엄격히 금지됩니다
- **상업적 이용 금지**: 영리 목적 사용이 불가능합니다
- **연구 목적 금지**: 학술 연구나 논문 작성에 사용할 수 없습니다
- **AI 학습 금지**: 다른 AI 모델 훈련에 사용할 수 없습니다

### 라이센스 문의

라이센스 범위를 벗어난 사용에 대한 문의사항은 다음으로 연락하세요:
- 이메일: junseong2im@gmail.com

### 사용된 오픈소스 라이센스

본 프로젝트는 다음 오픈소스 라이브러리들을 사용합니다 (각각의 라이센스에 따라 사용됨):
- Transformers (Apache 2.0)
- FastAPI (MIT)
- ChromaDB (Apache 2.0)
- Sentence-Transformers (Apache 2.0)

## 지원 및 문의

- **이슈 리포팅**: [GitHub Issues](https://github.com/junseong2im/innovative_perfume_ai/issues)
- **기능 요청**: [GitHub Discussions](https://github.com/junseong2im/innovative_perfume_ai/discussions)
- **이메일**: junseong2im@gmail.com

## 기술 스택

### 백엔드
- **FastAPI**: 고성능 비동기 웹 프레임워크
- **PyTorch**: 딥러닝 모델 추론 및 훈련
- **Transformers**: 최신 NLP 모델 (GPT, BERT)
- **Ollama**: 로컬 LLM 실행 플랫폼
- **PostgreSQL**: 메인 데이터베이스
- **Redis**: 캐시 및 세션 저장소
- **ChromaDB**: 벡터 데이터베이스

### 프론트엔드
- **Next.js 15**: React 기반 풀스택 프레임워크
- **TypeScript**: 타입 안정성
- **Tailwind CSS**: 유틸리티 기반 스타일링
- **Framer Motion**: 애니메이션

### DevOps
- **Docker**: 컨테이너화
- **GitHub Actions**: CI/CD 파이프라인
- **Prometheus/Grafana**: 모니터링
- **Kubernetes**: 오케스트레이션 (프로덕션)

## 감사의 말

이 프로젝트는 다음 오픈소스 프로젝트들의 도움을 받았습니다:

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [FastAPI](https://github.com/tiangolo/fastapi)
- [ChromaDB](https://github.com/chroma-core/chroma)
- [Sentence-Transformers](https://github.com/UKPLab/sentence-transformers)
- [Ollama](https://ollama.ai)

---

**Fragrance AI** - *창의적인 향수 레시피의 새로운 가능성을 열어갑니다*
