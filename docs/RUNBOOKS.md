# Artisan Runbooks

ìë™í™”ëœ ì¥ì•  ëŒ€ì‘ ì ˆì°¨

---

## ëª©ì°¨

1. [Qwen LLM Failure â†’ Downshift](#1-qwen-llm-failure--downshift)
2. [RL Reward Runaway â†’ Checkpoint Rollback](#2-rl-reward-runaway--checkpoint-rollback)
3. [API High Latency â†’ Scale Up](#3-api-high-latency--scale-up)
4. [Database Connection Failure](#4-database-connection-failure)
5. [Cache Service Failure](#5-cache-service-failure)

---

## 1. Qwen LLM Failure â†’ Downshift

**Runbook ID:** `qwen_failure_downshift`
**Severity:** Sev2
**Automation Level:** ìë™ (ìˆ˜ë™ í™•ì¸ 1ë‹¨ê³„)
**Expected Recovery Time:** 5ë¶„

### íŠ¸ë¦¬ê±° ì¡°ê±´

- Qwen health check 3íšŒ ì—°ì† ì‹¤íŒ¨
- Qwen API íƒ€ì„ì•„ì›ƒ > 30s
- Qwen ì—ëŸ¬ìœ¨ > 50% (5ë¶„ í‰ê· )

### ì¦ìƒ

- Creative mode API p95 latency > 10s
- Qwen ëª¨ë¸ ì‘ë‹µ ì—†ìŒ
- ì„œí‚·ë¸Œë ˆì´ì»¤ í™œì„±í™”

### ì‹¤í–‰ ë°©ë²•

```bash
# Dry run (ì‹œë®¬ë ˆì´ì…˜)
python -m fragrance_ai.sre.runbooks --execute qwen_failure_downshift --dry-run

# ì‹¤ì œ ì‹¤í–‰
python -m fragrance_ai.sre.runbooks --execute qwen_failure_downshift
```

### ë‹¨ê³„ë³„ ì ˆì°¨

#### Step 1: Verify Qwen Failure (ìë™)
```bash
# Health check
curl http://localhost:8000/health/llm?model=qwen

# Expected: status_code 503 or timeout
```

**í™•ì¸ ì‚¬í•­:**
- [ ] Qwen health check ì‹¤íŒ¨ 3íšŒ ì´ìƒ
- [ ] ìµœê·¼ 5ë¶„ ì—ëŸ¬ìœ¨ > 50%

#### Step 2: Enable Circuit Breaker (ìë™)
```python
from fragrance_ai.guards.circuit_breaker import get_circuit_breaker

breaker = get_circuit_breaker("qwen")
breaker.force_open()  # ì„œí‚·ë¸Œë ˆì´ì»¤ ê°•ì œ í™œì„±í™”
```

**ê²°ê³¼:**
- Qwenìœ¼ë¡œ ê°€ëŠ” ëª¨ë“  ìš”ì²­ ì°¨ë‹¨
- ìë™ìœ¼ë¡œ ëŒ€ì²´ ê²½ë¡œ í™œì„±í™”

#### Step 3: Downshift Creative â†’ Balanced (ìë™)
```python
from fragrance_ai.config.feature_flags import get_feature_flag_manager

manager = get_feature_flag_manager()
manager.set_downshift_mode("creative", "balanced")
# Creative ìš”ì²­ì„ Balanced ëª¨ë“œë¡œ ë¼ìš°íŒ…
```

**ê²°ê³¼:**
- Creative mode ìš”ì²­ì´ Balanced modeë¡œ ì²˜ë¦¬ë¨
- API ì§€ì—°ì‹œê°„ ê°ì†Œ (15s â†’ 3.2s)

#### Step 4: Check Balanced Health (ìë™)
```bash
curl http://localhost:8000/health/llm?model=mistral
curl http://localhost:8000/health/llm?model=llama

# Expected: status_code 200
```

**í™•ì¸ ì‚¬í•­:**
- [ ] Mistral ëª¨ë¸ ì •ìƒ
- [ ] Llama ëª¨ë¸ ì •ìƒ
- [ ] Balanced mode p95 < 3.5s

#### Step 5: Notify On-Call (ìë™)
```bash
# Slack ì•Œë¦¼ ìë™ ë°œì†¡
# PagerDuty alert ìë™ ë°œì†¡
```

**ì•Œë¦¼ ë‚´ìš©:**
- Qwen ì¥ì•  ë°œìƒ
- ìë™ìœ¼ë¡œ Balancedë¡œ ë‹¤ìš´ì‹œí”„íŠ¸ë¨
- ì˜¨ì½œ ì—”ì§€ë‹ˆì–´ ì¡°ì¹˜ í•„ìš”

#### Step 6: Create Incident (ìë™)
```bash
python -m fragrance_ai.sre.incident_manager --create '{
  "title": "Qwen LLM Failure - Downshifted to Balanced",
  "description": "Qwen model not responding. Auto-downshifted.",
  "severity": "Sev2",
  "components": ["LLM", "Qwen"]
}'
```

**ê²°ê³¼:**
- Sev2 ì‚¬ê±´ ìƒì„±
- íƒ€ì„ë¼ì¸ ê¸°ë¡ ì‹œì‘

### ìˆ˜ë™ ë³µêµ¬ ì ˆì°¨

#### ì˜¨ì½œ ì—”ì§€ë‹ˆì–´ ì¡°ì¹˜:

1. **Qwen ë¡œê·¸ í™•ì¸**
```bash
kubectl logs -n production deployment/qwen-llm --tail=100
```

2. **ê·¼ë³¸ ì›ì¸ íŒŒì•…**
- OOM (Out of Memory)?
- ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨?
- ë„¤íŠ¸ì›Œí¬ ì´ìŠˆ?

3. **Qwen ì¬ì‹œì‘**
```bash
kubectl rollout restart deployment/qwen-llm -n production
kubectl rollout status deployment/qwen-llm -n production
```

4. **Health check í™•ì¸**
```bash
# 5ë¶„ ëŒ€ê¸° í›„
curl http://localhost:8000/health/llm?model=qwen
```

5. **Creative mode ë³µì›**
```python
manager.restore_mode("creative")
breaker.close()  # ì„œí‚·ë¸Œë ˆì´ì»¤ ë‹«ê¸°
```

6. **ì‚¬ê±´ í•´ê²°**
```bash
python -m fragrance_ai.sre.incident_manager \
  --resolve INC-xxx \
  --resolution "Qwen restarted, Creative mode restored"
```

### ë¡¤ë°± ì ˆì°¨

```python
# ìë™ ë¡¤ë°±
manager.restore_mode("creative")
breaker.close()
```

### ì˜ˆë°© ì¡°ì¹˜

- [ ] Qwen ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ê°•í™”
- [ ] Qwen ìë™ ì¬ì‹œì‘ (liveness probe)
- [ ] Qwen ë¡œë“œ ë°¸ëŸ°ì‹± (ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤)

---

## 2. RL Reward Runaway â†’ Checkpoint Rollback

**Runbook ID:** `rl_reward_runaway_rollback`
**Severity:** Sev3
**Automation Level:** ë°˜ìë™ (ìˆ˜ë™ í™•ì¸ 2ë‹¨ê³„)
**Expected Recovery Time:** 15ë¶„

### íŠ¸ë¦¬ê±° ì¡°ê±´

- RL í‰ê·  ë³´ìƒ > 100 (ì •ìƒ: 10-20)
- RL ë³´ìƒ í‘œì¤€í¸ì°¨ > 50
- RL KL divergence > 0.1 (ì„ê³„ê°’: 0.03)

### ì¦ìƒ

- í•™ìŠµ ë¶ˆì•ˆì •
- ë³´ìƒ ê°’ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŒ
- ì§„í™” ê²°ê³¼ í’ˆì§ˆ ì €í•˜

### ì‹¤í–‰ ë°©ë²•

```bash
python -m fragrance_ai.sre.runbooks --execute rl_reward_runaway_rollback
```

### ë‹¨ê³„ë³„ ì ˆì°¨

#### Step 1: Verify Reward Runaway (ìë™)
```bash
# ìµœê·¼ 100 ì—í”¼ì†Œë“œ ë³´ìƒ í™•ì¸
python -c "
from fragrance_ai.training.rl.ppo import get_trainer
trainer = get_trainer()
stats = trainer.get_statistics()
print(f'Avg Reward: {stats[\"reward_mean\"]}')
print(f'Std Reward: {stats[\"reward_std\"]}')
"
```

**í™•ì¸ ì‚¬í•­:**
- [ ] í‰ê·  ë³´ìƒ > 100
- [ ] í‘œì¤€í¸ì°¨ > 50

#### Step 2: Stop RL Training (ìë™)
```bash
# í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
pkill -f "ppo_trainer"
```

**ê²°ê³¼:**
- ëª¨ë“  RL í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
- ì¶”ê°€ ë³´ìƒ í­ì£¼ ë°©ì§€

#### Step 3: Find Stable Checkpoint (ìë™)
```bash
python -c "
from fragrance_ai.training.checkpoint_manager import get_checkpoint_manager

manager = get_checkpoint_manager()
stable_checkpoint = manager.find_stable_checkpoint(
    kl_threshold=0.03,
    reward_min=10.0,
    reward_max=20.0
)
print(f'Found stable checkpoint: {stable_checkpoint}')
"
```

**ê¸°ì¤€:**
- KL divergence < 0.03
- Reward: 10.0 ~ 20.0
- ìµœì‹  ì•ˆì • ì²´í¬í¬ì¸íŠ¸ ì„ íƒ

#### Step 4: Rollback Checkpoint (ìˆ˜ë™ í™•ì¸ í•„ìš”)
```bash
# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
python -c "
from fragrance_ai.training.rl.ppo import get_trainer

trainer = get_trainer()
trainer.load_checkpoint('checkpoint_step_4500.pt')
print('Checkpoint loaded successfully')
"
```

**ìˆ˜ë™ í™•ì¸:**
```
âš ï¸  This will rollback training to checkpoint_step_4500.pt (2 hours ago).
   Current step: 5000
   Rollback to: 4500
   Progress lost: 500 steps (~30 minutes of training)

Proceed with rollback? (y/n):
```

#### Step 5: Verify Rollback (ìë™)
```bash
# ëª¨ë¸ ìƒíƒœ í™•ì¸
python -c "
from fragrance_ai.training.rl.ppo import get_trainer

trainer = get_trainer()
print(f'Current step: {trainer.global_step}')
print(f'Expected: 4500')
assert trainer.global_step == 4500
"
```

#### Step 6: Resume Training (ìë™)
```bash
# í•™ìŠµë¥  50% ê°ì†Œ í›„ ì¬ê°œ
python -c "
from fragrance_ai.training.rl.ppo import get_trainer

trainer = get_trainer()
trainer.set_learning_rate(trainer.learning_rate * 0.5)
print(f'Reduced LR: {trainer.learning_rate}')

trainer.resume_training()
print('Training resumed')
"
```

#### Step 7: Create Incident (ìë™)
```bash
python -m fragrance_ai.sre.incident_manager --create '{
  "title": "RL Reward Runaway - Checkpoint Rollback",
  "description": "RL training reward runaway. Rolled back to step 4500.",
  "severity": "Sev3",
  "components": ["RL", "PPO"]
}'
```

### ìˆ˜ë™ ë³µêµ¬ ì ˆì°¨

1. **ë³´ìƒ í•¨ìˆ˜ ê²€ì¦**
```python
# ë³´ìƒ ê³„ì‚° ë¡œì§ í™•ì¸
from fragrance_ai.training.rl.reward import calculate_reward

test_state = {...}
reward = calculate_reward(test_state)
print(f'Test reward: {reward}')
# Expected: 10-20 range
```

2. **í•™ìŠµë¥  ì¡°ì •**
```python
# ë” ë³´ìˆ˜ì ì¸ í•™ìŠµë¥ 
trainer.set_learning_rate(1e-5)  # Default: 3e-4
```

3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬ì¡°ì •**
```python
trainer.set_clip_epsilon(0.1)  # More conservative
trainer.set_entropy_coef(0.01)  # More exploration
```

### ì˜ˆë°© ì¡°ì¹˜

- [ ] ë³´ìƒ ìƒí•œì„  ì„¤ì • (max reward = 50)
- [ ] KL divergence ì•ŒëŒ (> 0.05)
- [ ] ìë™ ì²´í¬í¬ì¸íŠ¸ ê²€ì¦

---

## 3. API High Latency â†’ Scale Up

**Runbook ID:** `api_high_latency_scaleup`
**Severity:** Sev3
**Automation Level:** ìë™
**Expected Recovery Time:** 3ë¶„

### íŠ¸ë¦¬ê±° ì¡°ê±´

- API p95 latency > 5s (ì„ê³„ê°’: 2.5s)
- CPU ì‚¬ìš©ë¥  > 85%
- ìš”ì²­ ëŒ€ê¸°ì—´ > 100

### ì‹¤í–‰ ë°©ë²•

```bash
python -m fragrance_ai.sre.runbooks --execute api_high_latency_scaleup
```

### ë‹¨ê³„ë³„ ì ˆì°¨

#### Step 1: Verify High Latency
```bash
# Prometheus ì¿¼ë¦¬
curl -G http://prometheus:9090/api/v1/query \
  --data-urlencode 'query=histogram_quantile(0.95, rate(api_response_seconds_bucket[5m]))'
```

#### Step 2: Scale Up
```bash
# Kubernetes HPA ìˆ˜ë™ ìŠ¤ì¼€ì¼
kubectl scale deployment artisan-api --replicas=8 -n production
```

#### Step 3: Verify Improvement
```bash
# 5ë¶„ ëŒ€ê¸° í›„
curl -G http://prometheus:9090/api/v1/query \
  --data-urlencode 'query=histogram_quantile(0.95, rate(api_response_seconds_bucket[5m]))'
```

---

## 4. Database Connection Failure

**Runbook ID:** `database_connection_failure`
**Severity:** Sev1
**Automation Level:** ë°˜ìë™
**Expected Recovery Time:** 10ë¶„

### íŠ¸ë¦¬ê±° ì¡°ê±´

- Database connection pool exhausted
- Connection timeout > 5s
- ëª¨ë“  DB ì¿¼ë¦¬ ì‹¤íŒ¨

### ë‹¨ê³„ë³„ ì ˆì°¨

1. **Connection Pool ìƒíƒœ í™•ì¸**
2. **Database ì¬ì‹œì‘ (í•„ìš” ì‹œ)**
3. **Connection Pool ì¬ì„¤ì •**
4. **Read Replica í™œì„±í™”**

---

## 5. Cache Service Failure

**Runbook ID:** `cache_service_failure`
**Severity:** Sev3
**Automation Level:** ìë™
**Expected Recovery Time:** 2ë¶„

### íŠ¸ë¦¬ê±° ì¡°ê±´

- Redis connection ì‹¤íŒ¨
- Cache hit rate = 0%

### ë‹¨ê³„ë³„ ì ˆì°¨

1. **Cache bypass í™œì„±í™”** (ìë™)
2. **Redis health check**
3. **Redis ì¬ì‹œì‘ (í•„ìš” ì‹œ)**
4. **Cache warming**

---

## ëŸ°ë¶ í…ŒìŠ¤íŠ¸

### ì›”ê°„ ëŸ°ë¶ ë“œë¦´

ëª¨ë“  ëŸ°ë¶ì€ **ì›” 1íšŒ** í…ŒìŠ¤íŠ¸ ì‹¤í–‰:

```bash
# ëª¨ë“  ëŸ°ë¶ Dry run
for runbook in qwen_failure_downshift rl_reward_runaway_rollback api_high_latency_scaleup; do
  echo "Testing $runbook..."
  python -m fragrance_ai.sre.runbooks --execute $runbook --dry-run
done
```

### ëŸ°ë¶ ì—…ë°ì´íŠ¸ ì ˆì°¨

1. ì‚¬ê±´ ë°œìƒ í›„ ëŸ°ë¶ íš¨ê³¼ì„± í‰ê°€
2. ê°œì„  ì‚¬í•­ ì‹ë³„
3. ëŸ°ë¶ ì—…ë°ì´íŠ¸
4. Dry run í…ŒìŠ¤íŠ¸
5. íŒ€ ê³µìœ 

---

**ëŸ°ë¶ì€ ì‚´ì•„ìˆëŠ” ë¬¸ì„œì…ë‹ˆë‹¤. ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”!** ğŸ“–
